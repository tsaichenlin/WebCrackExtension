{"ast":null,"code":"import { OpenAI as OpenAIClient } from \"openai\";\nimport { GenerationChunk } from \"@langchain/core/outputs\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { LLM } from \"@langchain/core/language_models/llms\";\nimport { getEndpoint } from \"./utils/azure.js\";\nimport { wrapOpenAIClientError } from \"./utils/openai.js\";\n/**\n * @deprecated For legacy compatibility. Use ChatOpenAI instead.\n *\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n *\n * @augments BaseLLM\n * @augments OpenAIInput\n * @augments AzureOpenAIChatInput\n * @example\n * ```typescript\n * const model = new OpenAIChat({\n *   prefixMessages: [\n *     {\n *       role: \"system\",\n *       content: \"You are a helpful assistant that answers in pirate language\",\n *     },\n *   ],\n *   maxTokens: 50,\n * });\n *\n * const res = await model.call(\n *   \"What would be a good company name for a company that makes colorful socks?\"\n * );\n * console.log({ res });\n * ```\n */\nexport class OpenAIChat extends LLM {\n  static lc_name() {\n    return \"OpenAIChat\";\n  }\n  get callKeys() {\n    return [...super.callKeys, \"options\", \"promptIndex\"];\n  }\n  get lc_secrets() {\n    return {\n      openAIApiKey: \"OPENAI_API_KEY\",\n      azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n      organization: \"OPENAI_ORGANIZATION\"\n    };\n  }\n  get lc_aliases() {\n    return {\n      modelName: \"model\",\n      openAIApiKey: \"openai_api_key\",\n      azureOpenAIApiVersion: \"azure_openai_api_version\",\n      azureOpenAIApiKey: \"azure_openai_api_key\",\n      azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n      azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\"\n    };\n  }\n  constructor(fields, /** @deprecated */\n  configuration) {\n    super(fields ?? {});\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: true\n    });\n    Object.defineProperty(this, \"temperature\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"topP\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"frequencyPenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"presencePenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"n\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"logitBias\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"maxTokens\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"gpt-3.5-turbo\"\n    });\n    Object.defineProperty(this, \"prefixMessages\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelKwargs\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"timeout\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"stop\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"user\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"streaming\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    Object.defineProperty(this, \"openAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIBasePath\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"organization\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"client\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"clientConfig\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.openAIApiKey = fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n    this.azureOpenAIApiKey = fields?.azureOpenAIApiKey ?? getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n    if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n      throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n    }\n    this.azureOpenAIApiInstanceName = fields?.azureOpenAIApiInstanceName ?? getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n    this.azureOpenAIApiDeploymentName = (fields?.azureOpenAIApiCompletionsDeploymentName || fields?.azureOpenAIApiDeploymentName) ?? (getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") || getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"));\n    this.azureOpenAIApiVersion = fields?.azureOpenAIApiVersion ?? getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n    this.azureOpenAIBasePath = fields?.azureOpenAIBasePath ?? getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n    this.organization = fields?.configuration?.organization ?? getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n    this.modelName = fields?.modelName ?? this.modelName;\n    this.prefixMessages = fields?.prefixMessages ?? this.prefixMessages;\n    this.modelKwargs = fields?.modelKwargs ?? {};\n    this.timeout = fields?.timeout;\n    this.temperature = fields?.temperature ?? this.temperature;\n    this.topP = fields?.topP ?? this.topP;\n    this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n    this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n    this.n = fields?.n ?? this.n;\n    this.logitBias = fields?.logitBias;\n    this.maxTokens = fields?.maxTokens;\n    this.stop = fields?.stop;\n    this.user = fields?.user;\n    this.streaming = fields?.streaming ?? false;\n    if (this.n > 1) {\n      throw new Error(\"Cannot use n > 1 in OpenAIChat LLM. Use ChatOpenAI Chat Model instead.\");\n    }\n    if (this.azureOpenAIApiKey) {\n      if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n        throw new Error(\"Azure OpenAI API instance name not found\");\n      }\n      if (!this.azureOpenAIApiDeploymentName) {\n        throw new Error(\"Azure OpenAI API deployment name not found\");\n      }\n      if (!this.azureOpenAIApiVersion) {\n        throw new Error(\"Azure OpenAI API version not found\");\n      }\n      this.openAIApiKey = this.openAIApiKey ?? \"\";\n    }\n    this.clientConfig = {\n      apiKey: this.openAIApiKey,\n      organization: this.organization,\n      baseURL: configuration?.basePath ?? fields?.configuration?.basePath,\n      dangerouslyAllowBrowser: true,\n      defaultHeaders: configuration?.baseOptions?.headers ?? fields?.configuration?.baseOptions?.headers,\n      defaultQuery: configuration?.baseOptions?.params ?? fields?.configuration?.baseOptions?.params,\n      ...configuration,\n      ...fields?.configuration\n    };\n  }\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(options) {\n    return {\n      model: this.modelName,\n      temperature: this.temperature,\n      top_p: this.topP,\n      frequency_penalty: this.frequencyPenalty,\n      presence_penalty: this.presencePenalty,\n      n: this.n,\n      logit_bias: this.logitBias,\n      max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n      stop: options?.stop ?? this.stop,\n      user: this.user,\n      stream: this.streaming,\n      ...this.modelKwargs\n    };\n  }\n  /** @ignore */\n  _identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  /**\n   * Formats the messages for the OpenAI API.\n   * @param prompt The prompt to be formatted.\n   * @returns Array of formatted messages.\n   */\n  formatMessages(prompt) {\n    const message = {\n      role: \"user\",\n      content: prompt\n    };\n    return this.prefixMessages ? [...this.prefixMessages, message] : [message];\n  }\n  async *_streamResponseChunks(prompt, options, runManager) {\n    const params = {\n      ...this.invocationParams(options),\n      messages: this.formatMessages(prompt),\n      stream: true\n    };\n    const stream = await this.completionWithRetry(params, options);\n    for await (const data of stream) {\n      const choice = data?.choices[0];\n      if (!choice) {\n        continue;\n      }\n      const {\n        delta\n      } = choice;\n      const generationChunk = new GenerationChunk({\n        text: delta.content ?? \"\"\n      });\n      yield generationChunk;\n      const newTokenIndices = {\n        prompt: options.promptIndex ?? 0,\n        completion: choice.index ?? 0\n      };\n      // eslint-disable-next-line no-void\n      void runManager?.handleLLMNewToken(generationChunk.text ?? \"\", newTokenIndices);\n    }\n    if (options.signal?.aborted) {\n      throw new Error(\"AbortError\");\n    }\n  }\n  /** @ignore */\n  async _call(prompt, options, runManager) {\n    const params = this.invocationParams(options);\n    if (params.stream) {\n      const stream = await this._streamResponseChunks(prompt, options, runManager);\n      let finalChunk;\n      for await (const chunk of stream) {\n        if (finalChunk === undefined) {\n          finalChunk = chunk;\n        } else {\n          finalChunk = finalChunk.concat(chunk);\n        }\n      }\n      return finalChunk?.text ?? \"\";\n    } else {\n      const response = await this.completionWithRetry({\n        ...params,\n        stream: false,\n        messages: this.formatMessages(prompt)\n      }, {\n        signal: options.signal,\n        ...options.options\n      });\n      return response?.choices[0]?.message?.content ?? \"\";\n    }\n  }\n  async completionWithRetry(request, options) {\n    const requestOptions = this._getClientOptions(options);\n    return this.caller.call(async () => {\n      try {\n        const res = await this.client.chat.completions.create(request, requestOptions);\n        return res;\n      } catch (e) {\n        const error = wrapOpenAIClientError(e);\n        throw error;\n      }\n    });\n  }\n  /** @ignore */\n  _getClientOptions(options) {\n    if (!this.client) {\n      const openAIEndpointConfig = {\n        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n        azureOpenAIApiKey: this.azureOpenAIApiKey,\n        azureOpenAIBasePath: this.azureOpenAIBasePath,\n        baseURL: this.clientConfig.baseURL\n      };\n      const endpoint = getEndpoint(openAIEndpointConfig);\n      const params = {\n        ...this.clientConfig,\n        baseURL: endpoint,\n        timeout: this.timeout,\n        maxRetries: 0\n      };\n      if (!params.baseURL) {\n        delete params.baseURL;\n      }\n      this.client = new OpenAIClient(params);\n    }\n    const requestOptions = {\n      ...this.clientConfig,\n      ...options\n    };\n    if (this.azureOpenAIApiKey) {\n      requestOptions.headers = {\n        \"api-key\": this.azureOpenAIApiKey,\n        ...requestOptions.headers\n      };\n      requestOptions.query = {\n        \"api-version\": this.azureOpenAIApiVersion,\n        ...requestOptions.query\n      };\n    }\n    return requestOptions;\n  }\n  _llmType() {\n    return \"openai\";\n  }\n}","map":{"version":3,"names":["OpenAI","OpenAIClient","GenerationChunk","getEnvironmentVariable","LLM","getEndpoint","wrapOpenAIClientError","OpenAIChat","lc_name","callKeys","lc_secrets","openAIApiKey","azureOpenAIApiKey","organization","lc_aliases","modelName","azureOpenAIApiVersion","azureOpenAIApiInstanceName","azureOpenAIApiDeploymentName","constructor","fields","configuration","Object","defineProperty","enumerable","configurable","writable","value","Error","azureOpenAIApiCompletionsDeploymentName","azureOpenAIBasePath","prefixMessages","modelKwargs","timeout","temperature","topP","frequencyPenalty","presencePenalty","n","logitBias","maxTokens","stop","user","streaming","clientConfig","apiKey","baseURL","basePath","dangerouslyAllowBrowser","defaultHeaders","baseOptions","headers","defaultQuery","params","invocationParams","options","model","top_p","frequency_penalty","presence_penalty","logit_bias","max_tokens","undefined","stream","_identifyingParams","model_name","identifyingParams","formatMessages","prompt","message","role","content","_streamResponseChunks","runManager","messages","completionWithRetry","data","choice","choices","delta","generationChunk","text","newTokenIndices","promptIndex","completion","index","handleLLMNewToken","signal","aborted","_call","finalChunk","chunk","concat","response","request","requestOptions","_getClientOptions","caller","call","res","client","chat","completions","create","e","error","openAIEndpointConfig","endpoint","maxRetries","query","_llmType"],"sources":["/Users/mandylin/Desktop/WebCrack React/webcrack/node_modules/@langchain/openai/dist/legacy.js"],"sourcesContent":["import { OpenAI as OpenAIClient } from \"openai\";\nimport { GenerationChunk } from \"@langchain/core/outputs\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { LLM } from \"@langchain/core/language_models/llms\";\nimport { getEndpoint } from \"./utils/azure.js\";\nimport { wrapOpenAIClientError } from \"./utils/openai.js\";\n/**\n * @deprecated For legacy compatibility. Use ChatOpenAI instead.\n *\n * Wrapper around OpenAI large language models that use the Chat endpoint.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/chat/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n *\n * @augments BaseLLM\n * @augments OpenAIInput\n * @augments AzureOpenAIChatInput\n * @example\n * ```typescript\n * const model = new OpenAIChat({\n *   prefixMessages: [\n *     {\n *       role: \"system\",\n *       content: \"You are a helpful assistant that answers in pirate language\",\n *     },\n *   ],\n *   maxTokens: 50,\n * });\n *\n * const res = await model.call(\n *   \"What would be a good company name for a company that makes colorful socks?\"\n * );\n * console.log({ res });\n * ```\n */\nexport class OpenAIChat extends LLM {\n    static lc_name() {\n        return \"OpenAIChat\";\n    }\n    get callKeys() {\n        return [...super.callKeys, \"options\", \"promptIndex\"];\n    }\n    get lc_secrets() {\n        return {\n            openAIApiKey: \"OPENAI_API_KEY\",\n            azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n            organization: \"OPENAI_ORGANIZATION\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            modelName: \"model\",\n            openAIApiKey: \"openai_api_key\",\n            azureOpenAIApiVersion: \"azure_openai_api_version\",\n            azureOpenAIApiKey: \"azure_openai_api_key\",\n            azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n            azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\",\n        };\n    }\n    constructor(fields, \n    /** @deprecated */\n    configuration) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo\"\n        });\n        Object.defineProperty(this, \"prefixMessages\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"user\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"openAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIBasePath\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"organization\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.openAIApiKey =\n            fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n        this.azureOpenAIApiKey =\n            fields?.azureOpenAIApiKey ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n        if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n            throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n        }\n        this.azureOpenAIApiInstanceName =\n            fields?.azureOpenAIApiInstanceName ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n        this.azureOpenAIApiDeploymentName =\n            (fields?.azureOpenAIApiCompletionsDeploymentName ||\n                fields?.azureOpenAIApiDeploymentName) ??\n                (getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") ||\n                    getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"));\n        this.azureOpenAIApiVersion =\n            fields?.azureOpenAIApiVersion ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n        this.azureOpenAIBasePath =\n            fields?.azureOpenAIBasePath ??\n                getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n        this.organization =\n            fields?.configuration?.organization ??\n                getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.prefixMessages = fields?.prefixMessages ?? this.prefixMessages;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.n = fields?.n ?? this.n;\n        this.logitBias = fields?.logitBias;\n        this.maxTokens = fields?.maxTokens;\n        this.stop = fields?.stop;\n        this.user = fields?.user;\n        this.streaming = fields?.streaming ?? false;\n        if (this.n > 1) {\n            throw new Error(\"Cannot use n > 1 in OpenAIChat LLM. Use ChatOpenAI Chat Model instead.\");\n        }\n        if (this.azureOpenAIApiKey) {\n            if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n                throw new Error(\"Azure OpenAI API instance name not found\");\n            }\n            if (!this.azureOpenAIApiDeploymentName) {\n                throw new Error(\"Azure OpenAI API deployment name not found\");\n            }\n            if (!this.azureOpenAIApiVersion) {\n                throw new Error(\"Azure OpenAI API version not found\");\n            }\n            this.openAIApiKey = this.openAIApiKey ?? \"\";\n        }\n        this.clientConfig = {\n            apiKey: this.openAIApiKey,\n            organization: this.organization,\n            baseURL: configuration?.basePath ?? fields?.configuration?.basePath,\n            dangerouslyAllowBrowser: true,\n            defaultHeaders: configuration?.baseOptions?.headers ??\n                fields?.configuration?.baseOptions?.headers,\n            defaultQuery: configuration?.baseOptions?.params ??\n                fields?.configuration?.baseOptions?.params,\n            ...configuration,\n            ...fields?.configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options) {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            n: this.n,\n            logit_bias: this.logitBias,\n            max_tokens: this.maxTokens === -1 ? undefined : this.maxTokens,\n            stop: options?.stop ?? this.stop,\n            user: this.user,\n            stream: this.streaming,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Formats the messages for the OpenAI API.\n     * @param prompt The prompt to be formatted.\n     * @returns Array of formatted messages.\n     */\n    formatMessages(prompt) {\n        const message = {\n            role: \"user\",\n            content: prompt,\n        };\n        return this.prefixMessages ? [...this.prefixMessages, message] : [message];\n    }\n    async *_streamResponseChunks(prompt, options, runManager) {\n        const params = {\n            ...this.invocationParams(options),\n            messages: this.formatMessages(prompt),\n            stream: true,\n        };\n        const stream = await this.completionWithRetry(params, options);\n        for await (const data of stream) {\n            const choice = data?.choices[0];\n            if (!choice) {\n                continue;\n            }\n            const { delta } = choice;\n            const generationChunk = new GenerationChunk({\n                text: delta.content ?? \"\",\n            });\n            yield generationChunk;\n            const newTokenIndices = {\n                prompt: options.promptIndex ?? 0,\n                completion: choice.index ?? 0,\n            };\n            // eslint-disable-next-line no-void\n            void runManager?.handleLLMNewToken(generationChunk.text ?? \"\", newTokenIndices);\n        }\n        if (options.signal?.aborted) {\n            throw new Error(\"AbortError\");\n        }\n    }\n    /** @ignore */\n    async _call(prompt, options, runManager) {\n        const params = this.invocationParams(options);\n        if (params.stream) {\n            const stream = await this._streamResponseChunks(prompt, options, runManager);\n            let finalChunk;\n            for await (const chunk of stream) {\n                if (finalChunk === undefined) {\n                    finalChunk = chunk;\n                }\n                else {\n                    finalChunk = finalChunk.concat(chunk);\n                }\n            }\n            return finalChunk?.text ?? \"\";\n        }\n        else {\n            const response = await this.completionWithRetry({\n                ...params,\n                stream: false,\n                messages: this.formatMessages(prompt),\n            }, {\n                signal: options.signal,\n                ...options.options,\n            });\n            return response?.choices[0]?.message?.content ?? \"\";\n        }\n    }\n    async completionWithRetry(request, options) {\n        const requestOptions = this._getClientOptions(options);\n        return this.caller.call(async () => {\n            try {\n                const res = await this.client.chat.completions.create(request, requestOptions);\n                return res;\n            }\n            catch (e) {\n                const error = wrapOpenAIClientError(e);\n                throw error;\n            }\n        });\n    }\n    /** @ignore */\n    _getClientOptions(options) {\n        if (!this.client) {\n            const openAIEndpointConfig = {\n                azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n                azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n                azureOpenAIApiKey: this.azureOpenAIApiKey,\n                azureOpenAIBasePath: this.azureOpenAIBasePath,\n                baseURL: this.clientConfig.baseURL,\n            };\n            const endpoint = getEndpoint(openAIEndpointConfig);\n            const params = {\n                ...this.clientConfig,\n                baseURL: endpoint,\n                timeout: this.timeout,\n                maxRetries: 0,\n            };\n            if (!params.baseURL) {\n                delete params.baseURL;\n            }\n            this.client = new OpenAIClient(params);\n        }\n        const requestOptions = {\n            ...this.clientConfig,\n            ...options,\n        };\n        if (this.azureOpenAIApiKey) {\n            requestOptions.headers = {\n                \"api-key\": this.azureOpenAIApiKey,\n                ...requestOptions.headers,\n            };\n            requestOptions.query = {\n                \"api-version\": this.azureOpenAIApiVersion,\n                ...requestOptions.query,\n            };\n        }\n        return requestOptions;\n    }\n    _llmType() {\n        return \"openai\";\n    }\n}\n"],"mappings":"AAAA,SAASA,MAAM,IAAIC,YAAY,QAAQ,QAAQ;AAC/C,SAASC,eAAe,QAAQ,yBAAyB;AACzD,SAASC,sBAAsB,QAAQ,2BAA2B;AAClE,SAASC,GAAG,QAAQ,sCAAsC;AAC1D,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,SAASC,qBAAqB,QAAQ,mBAAmB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,UAAU,SAASH,GAAG,CAAC;EAChC,OAAOI,OAAOA,CAAA,EAAG;IACb,OAAO,YAAY;EACvB;EACA,IAAIC,QAAQA,CAAA,EAAG;IACX,OAAO,CAAC,GAAG,KAAK,CAACA,QAAQ,EAAE,SAAS,EAAE,aAAa,CAAC;EACxD;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,YAAY,EAAE,gBAAgB;MAC9BC,iBAAiB,EAAE,sBAAsB;MACzCC,YAAY,EAAE;IAClB,CAAC;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,SAAS,EAAE,OAAO;MAClBJ,YAAY,EAAE,gBAAgB;MAC9BK,qBAAqB,EAAE,0BAA0B;MACjDJ,iBAAiB,EAAE,sBAAsB;MACzCK,0BAA0B,EAAE,gCAAgC;MAC5DC,4BAA4B,EAAE;IAClC,CAAC;EACL;EACAC,WAAWA,CAACC,MAAM,EAClB;EACAC,aAAa,EAAE;IACX,KAAK,CAACD,MAAM,IAAI,CAAC,CAAC,CAAC;IACnBE,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,kBAAkB,EAAE;MAC5CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,GAAG,EAAE;MAC7BC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,gBAAgB,EAAE;MAC1CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,SAAS,EAAE;MACnCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,4BAA4B,EAAE;MACtDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,8BAA8B,EAAE;MACxDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAChB,YAAY,GACbS,MAAM,EAAET,YAAY,IAAIR,sBAAsB,CAAC,gBAAgB,CAAC;IACpE,IAAI,CAACS,iBAAiB,GAClBQ,MAAM,EAAER,iBAAiB,IACrBT,sBAAsB,CAAC,sBAAsB,CAAC;IACtD,IAAI,CAAC,IAAI,CAACS,iBAAiB,IAAI,CAAC,IAAI,CAACD,YAAY,EAAE;MAC/C,MAAM,IAAIiB,KAAK,CAAC,0CAA0C,CAAC;IAC/D;IACA,IAAI,CAACX,0BAA0B,GAC3BG,MAAM,EAAEH,0BAA0B,IAC9Bd,sBAAsB,CAAC,gCAAgC,CAAC;IAChE,IAAI,CAACe,4BAA4B,GAC7B,CAACE,MAAM,EAAES,uCAAuC,IAC5CT,MAAM,EAAEF,4BAA4B,MACnCf,sBAAsB,CAAC,8CAA8C,CAAC,IACnEA,sBAAsB,CAAC,kCAAkC,CAAC,CAAC;IACvE,IAAI,CAACa,qBAAqB,GACtBI,MAAM,EAAEJ,qBAAqB,IACzBb,sBAAsB,CAAC,0BAA0B,CAAC;IAC1D,IAAI,CAAC2B,mBAAmB,GACpBV,MAAM,EAAEU,mBAAmB,IACvB3B,sBAAsB,CAAC,wBAAwB,CAAC;IACxD,IAAI,CAACU,YAAY,GACbO,MAAM,EAAEC,aAAa,EAAER,YAAY,IAC/BV,sBAAsB,CAAC,qBAAqB,CAAC;IACrD,IAAI,CAACY,SAAS,GAAGK,MAAM,EAAEL,SAAS,IAAI,IAAI,CAACA,SAAS;IACpD,IAAI,CAACgB,cAAc,GAAGX,MAAM,EAAEW,cAAc,IAAI,IAAI,CAACA,cAAc;IACnE,IAAI,CAACC,WAAW,GAAGZ,MAAM,EAAEY,WAAW,IAAI,CAAC,CAAC;IAC5C,IAAI,CAACC,OAAO,GAAGb,MAAM,EAAEa,OAAO;IAC9B,IAAI,CAACC,WAAW,GAAGd,MAAM,EAAEc,WAAW,IAAI,IAAI,CAACA,WAAW;IAC1D,IAAI,CAACC,IAAI,GAAGf,MAAM,EAAEe,IAAI,IAAI,IAAI,CAACA,IAAI;IACrC,IAAI,CAACC,gBAAgB,GAAGhB,MAAM,EAAEgB,gBAAgB,IAAI,IAAI,CAACA,gBAAgB;IACzE,IAAI,CAACC,eAAe,GAAGjB,MAAM,EAAEiB,eAAe,IAAI,IAAI,CAACA,eAAe;IACtE,IAAI,CAACC,CAAC,GAAGlB,MAAM,EAAEkB,CAAC,IAAI,IAAI,CAACA,CAAC;IAC5B,IAAI,CAACC,SAAS,GAAGnB,MAAM,EAAEmB,SAAS;IAClC,IAAI,CAACC,SAAS,GAAGpB,MAAM,EAAEoB,SAAS;IAClC,IAAI,CAACC,IAAI,GAAGrB,MAAM,EAAEqB,IAAI;IACxB,IAAI,CAACC,IAAI,GAAGtB,MAAM,EAAEsB,IAAI;IACxB,IAAI,CAACC,SAAS,GAAGvB,MAAM,EAAEuB,SAAS,IAAI,KAAK;IAC3C,IAAI,IAAI,CAACL,CAAC,GAAG,CAAC,EAAE;MACZ,MAAM,IAAIV,KAAK,CAAC,wEAAwE,CAAC;IAC7F;IACA,IAAI,IAAI,CAAChB,iBAAiB,EAAE;MACxB,IAAI,CAAC,IAAI,CAACK,0BAA0B,IAAI,CAAC,IAAI,CAACa,mBAAmB,EAAE;QAC/D,MAAM,IAAIF,KAAK,CAAC,0CAA0C,CAAC;MAC/D;MACA,IAAI,CAAC,IAAI,CAACV,4BAA4B,EAAE;QACpC,MAAM,IAAIU,KAAK,CAAC,4CAA4C,CAAC;MACjE;MACA,IAAI,CAAC,IAAI,CAACZ,qBAAqB,EAAE;QAC7B,MAAM,IAAIY,KAAK,CAAC,oCAAoC,CAAC;MACzD;MACA,IAAI,CAACjB,YAAY,GAAG,IAAI,CAACA,YAAY,IAAI,EAAE;IAC/C;IACA,IAAI,CAACiC,YAAY,GAAG;MAChBC,MAAM,EAAE,IAAI,CAAClC,YAAY;MACzBE,YAAY,EAAE,IAAI,CAACA,YAAY;MAC/BiC,OAAO,EAAEzB,aAAa,EAAE0B,QAAQ,IAAI3B,MAAM,EAAEC,aAAa,EAAE0B,QAAQ;MACnEC,uBAAuB,EAAE,IAAI;MAC7BC,cAAc,EAAE5B,aAAa,EAAE6B,WAAW,EAAEC,OAAO,IAC/C/B,MAAM,EAAEC,aAAa,EAAE6B,WAAW,EAAEC,OAAO;MAC/CC,YAAY,EAAE/B,aAAa,EAAE6B,WAAW,EAAEG,MAAM,IAC5CjC,MAAM,EAAEC,aAAa,EAAE6B,WAAW,EAAEG,MAAM;MAC9C,GAAGhC,aAAa;MAChB,GAAGD,MAAM,EAAEC;IACf,CAAC;EACL;EACA;AACJ;AACA;EACIiC,gBAAgBA,CAACC,OAAO,EAAE;IACtB,OAAO;MACHC,KAAK,EAAE,IAAI,CAACzC,SAAS;MACrBmB,WAAW,EAAE,IAAI,CAACA,WAAW;MAC7BuB,KAAK,EAAE,IAAI,CAACtB,IAAI;MAChBuB,iBAAiB,EAAE,IAAI,CAACtB,gBAAgB;MACxCuB,gBAAgB,EAAE,IAAI,CAACtB,eAAe;MACtCC,CAAC,EAAE,IAAI,CAACA,CAAC;MACTsB,UAAU,EAAE,IAAI,CAACrB,SAAS;MAC1BsB,UAAU,EAAE,IAAI,CAACrB,SAAS,KAAK,CAAC,CAAC,GAAGsB,SAAS,GAAG,IAAI,CAACtB,SAAS;MAC9DC,IAAI,EAAEc,OAAO,EAAEd,IAAI,IAAI,IAAI,CAACA,IAAI;MAChCC,IAAI,EAAE,IAAI,CAACA,IAAI;MACfqB,MAAM,EAAE,IAAI,CAACpB,SAAS;MACtB,GAAG,IAAI,CAACX;IACZ,CAAC;EACL;EACA;EACAgC,kBAAkBA,CAAA,EAAG;IACjB,OAAO;MACHC,UAAU,EAAE,IAAI,CAAClD,SAAS;MAC1B,GAAG,IAAI,CAACuC,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACV;IACZ,CAAC;EACL;EACA;AACJ;AACA;EACIsB,iBAAiBA,CAAA,EAAG;IAChB,OAAO;MACHD,UAAU,EAAE,IAAI,CAAClD,SAAS;MAC1B,GAAG,IAAI,CAACuC,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACV;IACZ,CAAC;EACL;EACA;AACJ;AACA;AACA;AACA;EACIuB,cAAcA,CAACC,MAAM,EAAE;IACnB,MAAMC,OAAO,GAAG;MACZC,IAAI,EAAE,MAAM;MACZC,OAAO,EAAEH;IACb,CAAC;IACD,OAAO,IAAI,CAACrC,cAAc,GAAG,CAAC,GAAG,IAAI,CAACA,cAAc,EAAEsC,OAAO,CAAC,GAAG,CAACA,OAAO,CAAC;EAC9E;EACA,OAAOG,qBAAqBA,CAACJ,MAAM,EAAEb,OAAO,EAAEkB,UAAU,EAAE;IACtD,MAAMpB,MAAM,GAAG;MACX,GAAG,IAAI,CAACC,gBAAgB,CAACC,OAAO,CAAC;MACjCmB,QAAQ,EAAE,IAAI,CAACP,cAAc,CAACC,MAAM,CAAC;MACrCL,MAAM,EAAE;IACZ,CAAC;IACD,MAAMA,MAAM,GAAG,MAAM,IAAI,CAACY,mBAAmB,CAACtB,MAAM,EAAEE,OAAO,CAAC;IAC9D,WAAW,MAAMqB,IAAI,IAAIb,MAAM,EAAE;MAC7B,MAAMc,MAAM,GAAGD,IAAI,EAAEE,OAAO,CAAC,CAAC,CAAC;MAC/B,IAAI,CAACD,MAAM,EAAE;QACT;MACJ;MACA,MAAM;QAAEE;MAAM,CAAC,GAAGF,MAAM;MACxB,MAAMG,eAAe,GAAG,IAAI9E,eAAe,CAAC;QACxC+E,IAAI,EAAEF,KAAK,CAACR,OAAO,IAAI;MAC3B,CAAC,CAAC;MACF,MAAMS,eAAe;MACrB,MAAME,eAAe,GAAG;QACpBd,MAAM,EAAEb,OAAO,CAAC4B,WAAW,IAAI,CAAC;QAChCC,UAAU,EAAEP,MAAM,CAACQ,KAAK,IAAI;MAChC,CAAC;MACD;MACA,KAAKZ,UAAU,EAAEa,iBAAiB,CAACN,eAAe,CAACC,IAAI,IAAI,EAAE,EAAEC,eAAe,CAAC;IACnF;IACA,IAAI3B,OAAO,CAACgC,MAAM,EAAEC,OAAO,EAAE;MACzB,MAAM,IAAI5D,KAAK,CAAC,YAAY,CAAC;IACjC;EACJ;EACA;EACA,MAAM6D,KAAKA,CAACrB,MAAM,EAAEb,OAAO,EAAEkB,UAAU,EAAE;IACrC,MAAMpB,MAAM,GAAG,IAAI,CAACC,gBAAgB,CAACC,OAAO,CAAC;IAC7C,IAAIF,MAAM,CAACU,MAAM,EAAE;MACf,MAAMA,MAAM,GAAG,MAAM,IAAI,CAACS,qBAAqB,CAACJ,MAAM,EAAEb,OAAO,EAAEkB,UAAU,CAAC;MAC5E,IAAIiB,UAAU;MACd,WAAW,MAAMC,KAAK,IAAI5B,MAAM,EAAE;QAC9B,IAAI2B,UAAU,KAAK5B,SAAS,EAAE;UAC1B4B,UAAU,GAAGC,KAAK;QACtB,CAAC,MACI;UACDD,UAAU,GAAGA,UAAU,CAACE,MAAM,CAACD,KAAK,CAAC;QACzC;MACJ;MACA,OAAOD,UAAU,EAAET,IAAI,IAAI,EAAE;IACjC,CAAC,MACI;MACD,MAAMY,QAAQ,GAAG,MAAM,IAAI,CAAClB,mBAAmB,CAAC;QAC5C,GAAGtB,MAAM;QACTU,MAAM,EAAE,KAAK;QACbW,QAAQ,EAAE,IAAI,CAACP,cAAc,CAACC,MAAM;MACxC,CAAC,EAAE;QACCmB,MAAM,EAAEhC,OAAO,CAACgC,MAAM;QACtB,GAAGhC,OAAO,CAACA;MACf,CAAC,CAAC;MACF,OAAOsC,QAAQ,EAAEf,OAAO,CAAC,CAAC,CAAC,EAAET,OAAO,EAAEE,OAAO,IAAI,EAAE;IACvD;EACJ;EACA,MAAMI,mBAAmBA,CAACmB,OAAO,EAAEvC,OAAO,EAAE;IACxC,MAAMwC,cAAc,GAAG,IAAI,CAACC,iBAAiB,CAACzC,OAAO,CAAC;IACtD,OAAO,IAAI,CAAC0C,MAAM,CAACC,IAAI,CAAC,YAAY;MAChC,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAACC,MAAM,CAACC,IAAI,CAACC,WAAW,CAACC,MAAM,CAACT,OAAO,EAAEC,cAAc,CAAC;QAC9E,OAAOI,GAAG;MACd,CAAC,CACD,OAAOK,CAAC,EAAE;QACN,MAAMC,KAAK,GAAGnG,qBAAqB,CAACkG,CAAC,CAAC;QACtC,MAAMC,KAAK;MACf;IACJ,CAAC,CAAC;EACN;EACA;EACAT,iBAAiBA,CAACzC,OAAO,EAAE;IACvB,IAAI,CAAC,IAAI,CAAC6C,MAAM,EAAE;MACd,MAAMM,oBAAoB,GAAG;QACzBxF,4BAA4B,EAAE,IAAI,CAACA,4BAA4B;QAC/DD,0BAA0B,EAAE,IAAI,CAACA,0BAA0B;QAC3DL,iBAAiB,EAAE,IAAI,CAACA,iBAAiB;QACzCkB,mBAAmB,EAAE,IAAI,CAACA,mBAAmB;QAC7CgB,OAAO,EAAE,IAAI,CAACF,YAAY,CAACE;MAC/B,CAAC;MACD,MAAM6D,QAAQ,GAAGtG,WAAW,CAACqG,oBAAoB,CAAC;MAClD,MAAMrD,MAAM,GAAG;QACX,GAAG,IAAI,CAACT,YAAY;QACpBE,OAAO,EAAE6D,QAAQ;QACjB1E,OAAO,EAAE,IAAI,CAACA,OAAO;QACrB2E,UAAU,EAAE;MAChB,CAAC;MACD,IAAI,CAACvD,MAAM,CAACP,OAAO,EAAE;QACjB,OAAOO,MAAM,CAACP,OAAO;MACzB;MACA,IAAI,CAACsD,MAAM,GAAG,IAAInG,YAAY,CAACoD,MAAM,CAAC;IAC1C;IACA,MAAM0C,cAAc,GAAG;MACnB,GAAG,IAAI,CAACnD,YAAY;MACpB,GAAGW;IACP,CAAC;IACD,IAAI,IAAI,CAAC3C,iBAAiB,EAAE;MACxBmF,cAAc,CAAC5C,OAAO,GAAG;QACrB,SAAS,EAAE,IAAI,CAACvC,iBAAiB;QACjC,GAAGmF,cAAc,CAAC5C;MACtB,CAAC;MACD4C,cAAc,CAACc,KAAK,GAAG;QACnB,aAAa,EAAE,IAAI,CAAC7F,qBAAqB;QACzC,GAAG+E,cAAc,CAACc;MACtB,CAAC;IACL;IACA,OAAOd,cAAc;EACzB;EACAe,QAAQA,CAAA,EAAG;IACP,OAAO,QAAQ;EACnB;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}
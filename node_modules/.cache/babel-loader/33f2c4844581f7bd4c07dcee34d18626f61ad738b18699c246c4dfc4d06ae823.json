{"ast":null,"code":"import { Runnable } from \"../runnables/index.js\";\n/**\n * Abstract base class for parsing the output of a Large Language Model\n * (LLM) call. It provides methods for parsing the result of an LLM call\n * and invoking the parser with a given input.\n */\nexport class BaseLLMOutputParser extends Runnable {\n  /**\n   * Parses the result of an LLM call with a given prompt. By default, it\n   * simply calls `parseResult`.\n   * @param generations The generations from an LLM call.\n   * @param _prompt The prompt used in the LLM call.\n   * @param callbacks Optional callbacks.\n   * @returns A promise of the parsed output.\n   */\n  parseResultWithPrompt(generations, _prompt, callbacks) {\n    return this.parseResult(generations, callbacks);\n  }\n  /**\n   * Calls the parser with a given input and optional configuration options.\n   * If the input is a string, it creates a generation with the input as\n   * text and calls `parseResult`. If the input is a `BaseMessage`, it\n   * creates a generation with the input as a message and the content of the\n   * input as text, and then calls `parseResult`.\n   * @param input The input to the parser, which can be a string or a `BaseMessage`.\n   * @param options Optional configuration options.\n   * @returns A promise of the parsed output.\n   */\n  async invoke(input, options) {\n    if (typeof input === \"string\") {\n      return this._callWithConfig(async input => this.parseResult([{\n        text: input\n      }]), input, {\n        ...options,\n        runType: \"parser\"\n      });\n    } else {\n      return this._callWithConfig(async input => this.parseResult([{\n        message: input,\n        text: typeof input.content === \"string\" ? input.content : JSON.stringify(input.content)\n      }]), input, {\n        ...options,\n        runType: \"parser\"\n      });\n    }\n  }\n}\n/**\n * Class to parse the output of an LLM call.\n */\nexport class BaseOutputParser extends BaseLLMOutputParser {\n  parseResult(generations, callbacks) {\n    return this.parse(generations[0].text, callbacks);\n  }\n  async parseWithPrompt(text, _prompt, callbacks) {\n    return this.parse(text, callbacks);\n  }\n  /**\n   * Return the string type key uniquely identifying this class of parser\n   */\n  _type() {\n    throw new Error(\"_type not implemented\");\n  }\n}\n/**\n * Exception that output parsers should raise to signify a parsing error.\n *\n * This exists to differentiate parsing errors from other code or execution errors\n * that also may arise inside the output parser. OutputParserExceptions will be\n * available to catch and handle in ways to fix the parsing error, while other\n * errors will be raised.\n *\n * @param message - The error that's being re-raised or an error message.\n * @param llmOutput - String model output which is error-ing.\n * @param observation - String explanation of error which can be passed to a\n *     model to try and remediate the issue.\n * @param sendToLLM - Whether to send the observation and llm_output back to an Agent\n *     after an OutputParserException has been raised. This gives the underlying\n *     model driving the agent the context that the previous output was improperly\n *     structured, in the hopes that it will update the output to the correct\n *     format.\n */\nexport class OutputParserException extends Error {\n  constructor(message, llmOutput, observation, sendToLLM = false) {\n    super(message);\n    Object.defineProperty(this, \"llmOutput\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"observation\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"sendToLLM\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.llmOutput = llmOutput;\n    this.observation = observation;\n    this.sendToLLM = sendToLLM;\n    if (sendToLLM) {\n      if (observation === undefined || llmOutput === undefined) {\n        throw new Error(\"Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true\");\n      }\n    }\n  }\n}","map":{"version":3,"names":["Runnable","BaseLLMOutputParser","parseResultWithPrompt","generations","_prompt","callbacks","parseResult","invoke","input","options","_callWithConfig","text","runType","message","content","JSON","stringify","BaseOutputParser","parse","parseWithPrompt","_type","Error","OutputParserException","constructor","llmOutput","observation","sendToLLM","Object","defineProperty","enumerable","configurable","writable","value","undefined"],"sources":["/Users/mandylin/Desktop/WebCrack React/webcrack/node_modules/@langchain/core/dist/output_parsers/base.js"],"sourcesContent":["import { Runnable } from \"../runnables/index.js\";\n/**\n * Abstract base class for parsing the output of a Large Language Model\n * (LLM) call. It provides methods for parsing the result of an LLM call\n * and invoking the parser with a given input.\n */\nexport class BaseLLMOutputParser extends Runnable {\n    /**\n     * Parses the result of an LLM call with a given prompt. By default, it\n     * simply calls `parseResult`.\n     * @param generations The generations from an LLM call.\n     * @param _prompt The prompt used in the LLM call.\n     * @param callbacks Optional callbacks.\n     * @returns A promise of the parsed output.\n     */\n    parseResultWithPrompt(generations, _prompt, callbacks) {\n        return this.parseResult(generations, callbacks);\n    }\n    /**\n     * Calls the parser with a given input and optional configuration options.\n     * If the input is a string, it creates a generation with the input as\n     * text and calls `parseResult`. If the input is a `BaseMessage`, it\n     * creates a generation with the input as a message and the content of the\n     * input as text, and then calls `parseResult`.\n     * @param input The input to the parser, which can be a string or a `BaseMessage`.\n     * @param options Optional configuration options.\n     * @returns A promise of the parsed output.\n     */\n    async invoke(input, options) {\n        if (typeof input === \"string\") {\n            return this._callWithConfig(async (input) => this.parseResult([{ text: input }]), input, { ...options, runType: \"parser\" });\n        }\n        else {\n            return this._callWithConfig(async (input) => this.parseResult([\n                {\n                    message: input,\n                    text: typeof input.content === \"string\"\n                        ? input.content\n                        : JSON.stringify(input.content),\n                },\n            ]), input, { ...options, runType: \"parser\" });\n        }\n    }\n}\n/**\n * Class to parse the output of an LLM call.\n */\nexport class BaseOutputParser extends BaseLLMOutputParser {\n    parseResult(generations, callbacks) {\n        return this.parse(generations[0].text, callbacks);\n    }\n    async parseWithPrompt(text, _prompt, callbacks) {\n        return this.parse(text, callbacks);\n    }\n    /**\n     * Return the string type key uniquely identifying this class of parser\n     */\n    _type() {\n        throw new Error(\"_type not implemented\");\n    }\n}\n/**\n * Exception that output parsers should raise to signify a parsing error.\n *\n * This exists to differentiate parsing errors from other code or execution errors\n * that also may arise inside the output parser. OutputParserExceptions will be\n * available to catch and handle in ways to fix the parsing error, while other\n * errors will be raised.\n *\n * @param message - The error that's being re-raised or an error message.\n * @param llmOutput - String model output which is error-ing.\n * @param observation - String explanation of error which can be passed to a\n *     model to try and remediate the issue.\n * @param sendToLLM - Whether to send the observation and llm_output back to an Agent\n *     after an OutputParserException has been raised. This gives the underlying\n *     model driving the agent the context that the previous output was improperly\n *     structured, in the hopes that it will update the output to the correct\n *     format.\n */\nexport class OutputParserException extends Error {\n    constructor(message, llmOutput, observation, sendToLLM = false) {\n        super(message);\n        Object.defineProperty(this, \"llmOutput\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"observation\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"sendToLLM\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.llmOutput = llmOutput;\n        this.observation = observation;\n        this.sendToLLM = sendToLLM;\n        if (sendToLLM) {\n            if (observation === undefined || llmOutput === undefined) {\n                throw new Error(\"Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true\");\n            }\n        }\n    }\n}\n"],"mappings":"AAAA,SAASA,QAAQ,QAAQ,uBAAuB;AAChD;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,mBAAmB,SAASD,QAAQ,CAAC;EAC9C;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIE,qBAAqBA,CAACC,WAAW,EAAEC,OAAO,EAAEC,SAAS,EAAE;IACnD,OAAO,IAAI,CAACC,WAAW,CAACH,WAAW,EAAEE,SAAS,CAAC;EACnD;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAME,MAAMA,CAACC,KAAK,EAAEC,OAAO,EAAE;IACzB,IAAI,OAAOD,KAAK,KAAK,QAAQ,EAAE;MAC3B,OAAO,IAAI,CAACE,eAAe,CAAC,MAAOF,KAAK,IAAK,IAAI,CAACF,WAAW,CAAC,CAAC;QAAEK,IAAI,EAAEH;MAAM,CAAC,CAAC,CAAC,EAAEA,KAAK,EAAE;QAAE,GAAGC,OAAO;QAAEG,OAAO,EAAE;MAAS,CAAC,CAAC;IAC/H,CAAC,MACI;MACD,OAAO,IAAI,CAACF,eAAe,CAAC,MAAOF,KAAK,IAAK,IAAI,CAACF,WAAW,CAAC,CAC1D;QACIO,OAAO,EAAEL,KAAK;QACdG,IAAI,EAAE,OAAOH,KAAK,CAACM,OAAO,KAAK,QAAQ,GACjCN,KAAK,CAACM,OAAO,GACbC,IAAI,CAACC,SAAS,CAACR,KAAK,CAACM,OAAO;MACtC,CAAC,CACJ,CAAC,EAAEN,KAAK,EAAE;QAAE,GAAGC,OAAO;QAAEG,OAAO,EAAE;MAAS,CAAC,CAAC;IACjD;EACJ;AACJ;AACA;AACA;AACA;AACA,OAAO,MAAMK,gBAAgB,SAAShB,mBAAmB,CAAC;EACtDK,WAAWA,CAACH,WAAW,EAAEE,SAAS,EAAE;IAChC,OAAO,IAAI,CAACa,KAAK,CAACf,WAAW,CAAC,CAAC,CAAC,CAACQ,IAAI,EAAEN,SAAS,CAAC;EACrD;EACA,MAAMc,eAAeA,CAACR,IAAI,EAAEP,OAAO,EAAEC,SAAS,EAAE;IAC5C,OAAO,IAAI,CAACa,KAAK,CAACP,IAAI,EAAEN,SAAS,CAAC;EACtC;EACA;AACJ;AACA;EACIe,KAAKA,CAAA,EAAG;IACJ,MAAM,IAAIC,KAAK,CAAC,uBAAuB,CAAC;EAC5C;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,qBAAqB,SAASD,KAAK,CAAC;EAC7CE,WAAWA,CAACV,OAAO,EAAEW,SAAS,EAAEC,WAAW,EAAEC,SAAS,GAAG,KAAK,EAAE;IAC5D,KAAK,CAACb,OAAO,CAAC;IACdc,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAACR,SAAS,GAAGA,SAAS;IAC1B,IAAI,CAACC,WAAW,GAAGA,WAAW;IAC9B,IAAI,CAACC,SAAS,GAAGA,SAAS;IAC1B,IAAIA,SAAS,EAAE;MACX,IAAID,WAAW,KAAKQ,SAAS,IAAIT,SAAS,KAAKS,SAAS,EAAE;QACtD,MAAM,IAAIZ,KAAK,CAAC,2EAA2E,CAAC;MAChG;IACJ;EACJ;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}
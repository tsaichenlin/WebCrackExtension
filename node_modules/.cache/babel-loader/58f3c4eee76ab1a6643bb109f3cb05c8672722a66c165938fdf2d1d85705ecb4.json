{"ast":null,"code":"import{extract}from\"@extractus/article-extractor\";import{PromptTemplate}from\"@langchain/core/prompts\";import{ChatOpenAI}from\"@langchain/openai\";import{SupabaseVectorStore}from\"@langchain/community/vectorstores/supabase\";import{OpenAIEmbeddings}from\"@langchain/openai\";import{createClient}from\"@supabase/supabase-js\";import{StringOutputParser}from\"@langchain/core/output_parsers\";import{RunnableSequence}from\"@langchain/core/runnables\";import{RunnablePassthrough}from\"@langchain/core/runnables\";async function extractor(){const input=\"https://www.bbc.com/news/world-europe-68323366\";var article=\"\";// here we use top-level await, assume current platform supports it\ntry{article=await extract(input);}catch(err){console.error(err);}// console.log(article);\nlet curr_article={title:article.title,author:article.author,publish_date:article.published,content:article.content,topics:[],genre:\"\",key_word_search:\"\"};// console.log(curr_article);\nconst openAIAPIKey=\"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\";const embeddings=new OpenAIEmbeddings({openAIApiKey:openAIAPIKey});const llm=new ChatOpenAI({openAIApiKey:openAIAPIKey});const testTemplate=\"given the content of the file, only produce the content as a string without the html tags and tabs. \\\n                        Include a list of topics discussed in the article.    \\\n                        Also identify the genre of the article (e.g. political, health, science)      \\\n                        Come up with a 5 key word search for google to find out more information about the article. \\\n                        Format the output in json to be a dictionary containing content (content), topics (topic), genre (genre), \\\n                        and one sentence to inquire further about the article (key_word_search).\\\n                        The variable names are defined in parentheses for each entry in the dictionary. \\\n                        The content will be a string, topics will be a list of a string of topics, \\\n                        genre will be a string, and the key_word_search will be a string. file:{file} article:\";const testPrompt=PromptTemplate.fromTemplate(testTemplate);const testchain=RunnableSequence.from([testPrompt,llm,new StringOutputParser()]);const response=await testchain.invoke({file:article.content});console.log(response);var output=JSON.parse(response);// console.log(output);\n// console.log(output.content);\n// console.log(output.topics);\ncurr_article.content=output.content;curr_article.topics=output.topics;curr_article.genre=output.genre;curr_article.key_word_search=output.key_word_search;console.log(curr_article);}export default extractor;","map":{"version":3,"names":["extract","PromptTemplate","ChatOpenAI","SupabaseVectorStore","OpenAIEmbeddings","createClient","StringOutputParser","RunnableSequence","RunnablePassthrough","extractor","input","article","err","console","error","curr_article","title","author","publish_date","published","content","topics","genre","key_word_search","openAIAPIKey","embeddings","openAIApiKey","llm","testTemplate","testPrompt","fromTemplate","testchain","from","response","invoke","file","log","output","JSON","parse"],"sources":["/Users/mandylin/Desktop/WebCrack React/webcrack/src/extractor.mjs"],"sourcesContent":["import { extract } from \"@extractus/article-extractor\";\nimport { PromptTemplate } from \"@langchain/core/prompts\";\nimport { ChatOpenAI } from \"@langchain/openai\";\nimport { SupabaseVectorStore } from \"@langchain/community/vectorstores/supabase\";\nimport { OpenAIEmbeddings } from \"@langchain/openai\";\nimport { createClient } from \"@supabase/supabase-js\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport { RunnableSequence } from \"@langchain/core/runnables\";\nimport { RunnablePassthrough } from \"@langchain/core/runnables\";\n\nasync function extractor() {\n  const input = \"https://www.bbc.com/news/world-europe-68323366\";\n\n  var article = \"\";\n  // here we use top-level await, assume current platform supports it\n  try {\n    article = await extract(input);\n  } catch (err) {\n    console.error(err);\n  }\n\n  // console.log(article);\n  let curr_article = {\n    title: article.title,\n    author: article.author,\n    publish_date: article.published,\n    content: article.content,\n    topics: [],\n    genre: \"\",\n    key_word_search: \"\",\n  };\n  // console.log(curr_article);\n\n  const openAIAPIKey = \"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\";\n  const embeddings = new OpenAIEmbeddings({ openAIApiKey: openAIAPIKey });\n\n  const llm = new ChatOpenAI({ openAIApiKey: openAIAPIKey });\n\n  const testTemplate =\n    \"given the content of the file, only produce the content as a string without the html tags and tabs. \\\n                        Include a list of topics discussed in the article.    \\\n                        Also identify the genre of the article (e.g. political, health, science)      \\\n                        Come up with a 5 key word search for google to find out more information about the article. \\\n                        Format the output in json to be a dictionary containing content (content), topics (topic), genre (genre), \\\n                        and one sentence to inquire further about the article (key_word_search).\\\n                        The variable names are defined in parentheses for each entry in the dictionary. \\\n                        The content will be a string, topics will be a list of a string of topics, \\\n                        genre will be a string, and the key_word_search will be a string. file:{file} article:\";\n\n  const testPrompt = PromptTemplate.fromTemplate(testTemplate);\n  const testchain = RunnableSequence.from([\n    testPrompt,\n    llm,\n    new StringOutputParser(),\n  ]);\n\n  const response = await testchain.invoke({ file: article.content });\n\n  console.log(response);\n\n  var output = JSON.parse(response);\n\n  // console.log(output);\n  // console.log(output.content);\n  // console.log(output.topics);\n\n  curr_article.content = output.content;\n  curr_article.topics = output.topics;\n  curr_article.genre = output.genre;\n  curr_article.key_word_search = output.key_word_search;\n  console.log(curr_article);\n}\n\nexport default extractor;\n"],"mappings":"AAAA,OAASA,OAAO,KAAQ,8BAA8B,CACtD,OAASC,cAAc,KAAQ,yBAAyB,CACxD,OAASC,UAAU,KAAQ,mBAAmB,CAC9C,OAASC,mBAAmB,KAAQ,4CAA4C,CAChF,OAASC,gBAAgB,KAAQ,mBAAmB,CACpD,OAASC,YAAY,KAAQ,uBAAuB,CACpD,OAASC,kBAAkB,KAAQ,gCAAgC,CACnE,OAASC,gBAAgB,KAAQ,2BAA2B,CAC5D,OAASC,mBAAmB,KAAQ,2BAA2B,CAE/D,cAAe,CAAAC,SAASA,CAAA,CAAG,CACzB,KAAM,CAAAC,KAAK,CAAG,gDAAgD,CAE9D,GAAI,CAAAC,OAAO,CAAG,EAAE,CAChB;AACA,GAAI,CACFA,OAAO,CAAG,KAAM,CAAAX,OAAO,CAACU,KAAK,CAAC,CAChC,CAAE,MAAOE,GAAG,CAAE,CACZC,OAAO,CAACC,KAAK,CAACF,GAAG,CAAC,CACpB,CAEA;AACA,GAAI,CAAAG,YAAY,CAAG,CACjBC,KAAK,CAAEL,OAAO,CAACK,KAAK,CACpBC,MAAM,CAAEN,OAAO,CAACM,MAAM,CACtBC,YAAY,CAAEP,OAAO,CAACQ,SAAS,CAC/BC,OAAO,CAAET,OAAO,CAACS,OAAO,CACxBC,MAAM,CAAE,EAAE,CACVC,KAAK,CAAE,EAAE,CACTC,eAAe,CAAE,EACnB,CAAC,CACD;AAEA,KAAM,CAAAC,YAAY,CAAG,qDAAqD,CAC1E,KAAM,CAAAC,UAAU,CAAG,GAAI,CAAArB,gBAAgB,CAAC,CAAEsB,YAAY,CAAEF,YAAa,CAAC,CAAC,CAEvE,KAAM,CAAAG,GAAG,CAAG,GAAI,CAAAzB,UAAU,CAAC,CAAEwB,YAAY,CAAEF,YAAa,CAAC,CAAC,CAE1D,KAAM,CAAAI,YAAY,CAChB;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+GAA+G,CAE7G,KAAM,CAAAC,UAAU,CAAG5B,cAAc,CAAC6B,YAAY,CAACF,YAAY,CAAC,CAC5D,KAAM,CAAAG,SAAS,CAAGxB,gBAAgB,CAACyB,IAAI,CAAC,CACtCH,UAAU,CACVF,GAAG,CACH,GAAI,CAAArB,kBAAkB,CAAC,CAAC,CACzB,CAAC,CAEF,KAAM,CAAA2B,QAAQ,CAAG,KAAM,CAAAF,SAAS,CAACG,MAAM,CAAC,CAAEC,IAAI,CAAExB,OAAO,CAACS,OAAQ,CAAC,CAAC,CAElEP,OAAO,CAACuB,GAAG,CAACH,QAAQ,CAAC,CAErB,GAAI,CAAAI,MAAM,CAAGC,IAAI,CAACC,KAAK,CAACN,QAAQ,CAAC,CAEjC;AACA;AACA;AAEAlB,YAAY,CAACK,OAAO,CAAGiB,MAAM,CAACjB,OAAO,CACrCL,YAAY,CAACM,MAAM,CAAGgB,MAAM,CAAChB,MAAM,CACnCN,YAAY,CAACO,KAAK,CAAGe,MAAM,CAACf,KAAK,CACjCP,YAAY,CAACQ,eAAe,CAAGc,MAAM,CAACd,eAAe,CACrDV,OAAO,CAACuB,GAAG,CAACrB,YAAY,CAAC,CAC3B,CAEA,cAAe,CAAAN,SAAS"},"metadata":{},"sourceType":"module","externalDependencies":[]}
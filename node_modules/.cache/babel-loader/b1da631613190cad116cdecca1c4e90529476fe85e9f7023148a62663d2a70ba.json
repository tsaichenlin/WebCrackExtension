{"ast":null,"code":"import { OpenAI as OpenAIClient } from \"openai\";\nimport { calculateMaxTokens } from \"@langchain/core/language_models/base\";\nimport { GenerationChunk } from \"@langchain/core/outputs\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { BaseLLM } from \"@langchain/core/language_models/llms\";\nimport { chunkArray } from \"@langchain/core/utils/chunk_array\";\nimport { getEndpoint } from \"./utils/azure.js\";\nimport { OpenAIChat } from \"./legacy.js\";\nimport { wrapOpenAIClientError } from \"./utils/openai.js\";\nexport { OpenAIChat };\n/**\n * Wrapper around OpenAI large language models.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/completions/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n * @example\n * ```typescript\n * const model = new OpenAI({\n *   modelName: \"gpt-4\",\n *   temperature: 0.7,\n *   maxTokens: 1000,\n *   maxRetries: 5,\n * });\n *\n * const res = await model.call(\n *   \"Question: What would be a good company name for a company that makes colorful socks?\\nAnswer:\"\n * );\n * console.log({ res });\n * ```\n */\nexport class OpenAI extends BaseLLM {\n  static lc_name() {\n    return \"OpenAI\";\n  }\n  get callKeys() {\n    return [...super.callKeys, \"options\"];\n  }\n  get lc_secrets() {\n    return {\n      openAIApiKey: \"OPENAI_API_KEY\",\n      azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n      organization: \"OPENAI_ORGANIZATION\"\n    };\n  }\n  get lc_aliases() {\n    return {\n      modelName: \"model\",\n      openAIApiKey: \"openai_api_key\",\n      azureOpenAIApiVersion: \"azure_openai_api_version\",\n      azureOpenAIApiKey: \"azure_openai_api_key\",\n      azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n      azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\"\n    };\n  }\n  constructor(fields, /** @deprecated */\n  configuration) {\n    var _fields$modelName, _fields$modelName2, _fields$modelName3, _fields$openAIApiKey, _fields$azureOpenAIAp, _fields$azureOpenAIAp2, _ref, _fields$azureOpenAIAp3, _fields$azureOpenAIBa, _fields$configuration, _fields$configuration2, _fields$modelName4, _fields$modelKwargs, _fields$batchSize, _fields$temperature, _fields$maxTokens, _fields$topP, _fields$frequencyPena, _fields$presencePenal, _fields$n, _fields$bestOf, _fields$streaming, _configuration$basePa, _fields$configuration3, _configuration$baseOp, _configuration$baseOp2, _fields$configuration4, _configuration$baseOp3, _configuration$baseOp4, _fields$configuration5;\n    if ((fields !== null && fields !== void 0 && (_fields$modelName = fields.modelName) !== null && _fields$modelName !== void 0 && _fields$modelName.startsWith(\"gpt-3.5-turbo\") || fields !== null && fields !== void 0 && (_fields$modelName2 = fields.modelName) !== null && _fields$modelName2 !== void 0 && _fields$modelName2.startsWith(\"gpt-4\")) && !(fields !== null && fields !== void 0 && (_fields$modelName3 = fields.modelName) !== null && _fields$modelName3 !== void 0 && _fields$modelName3.includes(\"-instruct\"))) {\n      // eslint-disable-next-line no-constructor-return\n      return new OpenAIChat(fields, configuration);\n    }\n    super(fields !== null && fields !== void 0 ? fields : {});\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: true\n    });\n    Object.defineProperty(this, \"temperature\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0.7\n    });\n    Object.defineProperty(this, \"maxTokens\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 256\n    });\n    Object.defineProperty(this, \"topP\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"frequencyPenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"presencePenalty\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 0\n    });\n    Object.defineProperty(this, \"n\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 1\n    });\n    Object.defineProperty(this, \"bestOf\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"logitBias\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"modelName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"gpt-3.5-turbo-instruct\"\n    });\n    Object.defineProperty(this, \"modelKwargs\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"batchSize\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: 20\n    });\n    Object.defineProperty(this, \"timeout\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"stop\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"user\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"streaming\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    Object.defineProperty(this, \"openAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"azureOpenAIBasePath\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"organization\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"client\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"clientConfig\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.openAIApiKey = (_fields$openAIApiKey = fields === null || fields === void 0 ? void 0 : fields.openAIApiKey) !== null && _fields$openAIApiKey !== void 0 ? _fields$openAIApiKey : getEnvironmentVariable(\"OPENAI_API_KEY\");\n    this.azureOpenAIApiKey = (_fields$azureOpenAIAp = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiKey) !== null && _fields$azureOpenAIAp !== void 0 ? _fields$azureOpenAIAp : getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n    if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n      throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n    }\n    this.azureOpenAIApiInstanceName = (_fields$azureOpenAIAp2 = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiInstanceName) !== null && _fields$azureOpenAIAp2 !== void 0 ? _fields$azureOpenAIAp2 : getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n    this.azureOpenAIApiDeploymentName = (_ref = (fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiCompletionsDeploymentName) || (fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiDeploymentName)) !== null && _ref !== void 0 ? _ref : getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") || getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\");\n    this.azureOpenAIApiVersion = (_fields$azureOpenAIAp3 = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIApiVersion) !== null && _fields$azureOpenAIAp3 !== void 0 ? _fields$azureOpenAIAp3 : getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n    this.azureOpenAIBasePath = (_fields$azureOpenAIBa = fields === null || fields === void 0 ? void 0 : fields.azureOpenAIBasePath) !== null && _fields$azureOpenAIBa !== void 0 ? _fields$azureOpenAIBa : getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n    this.organization = (_fields$configuration = fields === null || fields === void 0 || (_fields$configuration2 = fields.configuration) === null || _fields$configuration2 === void 0 ? void 0 : _fields$configuration2.organization) !== null && _fields$configuration !== void 0 ? _fields$configuration : getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n    this.modelName = (_fields$modelName4 = fields === null || fields === void 0 ? void 0 : fields.modelName) !== null && _fields$modelName4 !== void 0 ? _fields$modelName4 : this.modelName;\n    this.modelKwargs = (_fields$modelKwargs = fields === null || fields === void 0 ? void 0 : fields.modelKwargs) !== null && _fields$modelKwargs !== void 0 ? _fields$modelKwargs : {};\n    this.batchSize = (_fields$batchSize = fields === null || fields === void 0 ? void 0 : fields.batchSize) !== null && _fields$batchSize !== void 0 ? _fields$batchSize : this.batchSize;\n    this.timeout = fields === null || fields === void 0 ? void 0 : fields.timeout;\n    this.temperature = (_fields$temperature = fields === null || fields === void 0 ? void 0 : fields.temperature) !== null && _fields$temperature !== void 0 ? _fields$temperature : this.temperature;\n    this.maxTokens = (_fields$maxTokens = fields === null || fields === void 0 ? void 0 : fields.maxTokens) !== null && _fields$maxTokens !== void 0 ? _fields$maxTokens : this.maxTokens;\n    this.topP = (_fields$topP = fields === null || fields === void 0 ? void 0 : fields.topP) !== null && _fields$topP !== void 0 ? _fields$topP : this.topP;\n    this.frequencyPenalty = (_fields$frequencyPena = fields === null || fields === void 0 ? void 0 : fields.frequencyPenalty) !== null && _fields$frequencyPena !== void 0 ? _fields$frequencyPena : this.frequencyPenalty;\n    this.presencePenalty = (_fields$presencePenal = fields === null || fields === void 0 ? void 0 : fields.presencePenalty) !== null && _fields$presencePenal !== void 0 ? _fields$presencePenal : this.presencePenalty;\n    this.n = (_fields$n = fields === null || fields === void 0 ? void 0 : fields.n) !== null && _fields$n !== void 0 ? _fields$n : this.n;\n    this.bestOf = (_fields$bestOf = fields === null || fields === void 0 ? void 0 : fields.bestOf) !== null && _fields$bestOf !== void 0 ? _fields$bestOf : this.bestOf;\n    this.logitBias = fields === null || fields === void 0 ? void 0 : fields.logitBias;\n    this.stop = fields === null || fields === void 0 ? void 0 : fields.stop;\n    this.user = fields === null || fields === void 0 ? void 0 : fields.user;\n    this.streaming = (_fields$streaming = fields === null || fields === void 0 ? void 0 : fields.streaming) !== null && _fields$streaming !== void 0 ? _fields$streaming : false;\n    if (this.streaming && this.bestOf && this.bestOf > 1) {\n      throw new Error(\"Cannot stream results when bestOf > 1\");\n    }\n    if (this.azureOpenAIApiKey) {\n      var _this$openAIApiKey;\n      if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n        throw new Error(\"Azure OpenAI API instance name not found\");\n      }\n      if (!this.azureOpenAIApiDeploymentName) {\n        throw new Error(\"Azure OpenAI API deployment name not found\");\n      }\n      if (!this.azureOpenAIApiVersion) {\n        throw new Error(\"Azure OpenAI API version not found\");\n      }\n      this.openAIApiKey = (_this$openAIApiKey = this.openAIApiKey) !== null && _this$openAIApiKey !== void 0 ? _this$openAIApiKey : \"\";\n    }\n    this.clientConfig = {\n      apiKey: this.openAIApiKey,\n      organization: this.organization,\n      baseURL: (_configuration$basePa = configuration === null || configuration === void 0 ? void 0 : configuration.basePath) !== null && _configuration$basePa !== void 0 ? _configuration$basePa : fields === null || fields === void 0 || (_fields$configuration3 = fields.configuration) === null || _fields$configuration3 === void 0 ? void 0 : _fields$configuration3.basePath,\n      dangerouslyAllowBrowser: true,\n      defaultHeaders: (_configuration$baseOp = configuration === null || configuration === void 0 || (_configuration$baseOp2 = configuration.baseOptions) === null || _configuration$baseOp2 === void 0 ? void 0 : _configuration$baseOp2.headers) !== null && _configuration$baseOp !== void 0 ? _configuration$baseOp : fields === null || fields === void 0 || (_fields$configuration4 = fields.configuration) === null || _fields$configuration4 === void 0 || (_fields$configuration4 = _fields$configuration4.baseOptions) === null || _fields$configuration4 === void 0 ? void 0 : _fields$configuration4.headers,\n      defaultQuery: (_configuration$baseOp3 = configuration === null || configuration === void 0 || (_configuration$baseOp4 = configuration.baseOptions) === null || _configuration$baseOp4 === void 0 ? void 0 : _configuration$baseOp4.params) !== null && _configuration$baseOp3 !== void 0 ? _configuration$baseOp3 : fields === null || fields === void 0 || (_fields$configuration5 = fields.configuration) === null || _fields$configuration5 === void 0 || (_fields$configuration5 = _fields$configuration5.baseOptions) === null || _fields$configuration5 === void 0 ? void 0 : _fields$configuration5.params,\n      ...configuration,\n      ...(fields === null || fields === void 0 ? void 0 : fields.configuration)\n    };\n  }\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(options) {\n    var _options$stop;\n    return {\n      model: this.modelName,\n      temperature: this.temperature,\n      max_tokens: this.maxTokens,\n      top_p: this.topP,\n      frequency_penalty: this.frequencyPenalty,\n      presence_penalty: this.presencePenalty,\n      n: this.n,\n      best_of: this.bestOf,\n      logit_bias: this.logitBias,\n      stop: (_options$stop = options === null || options === void 0 ? void 0 : options.stop) !== null && _options$stop !== void 0 ? _options$stop : this.stop,\n      user: this.user,\n      stream: this.streaming,\n      ...this.modelKwargs\n    };\n  }\n  /** @ignore */\n  _identifyingParams() {\n    return {\n      model_name: this.modelName,\n      ...this.invocationParams(),\n      ...this.clientConfig\n    };\n  }\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams() {\n    return this._identifyingParams();\n  }\n  /**\n   * Call out to OpenAI's endpoint with k unique prompts\n   *\n   * @param [prompts] - The prompts to pass into the model.\n   * @param [options] - Optional list of stop words to use when generating.\n   * @param [runManager] - Optional callback manager to use when generating.\n   *\n   * @returns The full LLM output.\n   *\n   * @example\n   * ```ts\n   * import { OpenAI } from \"langchain/llms/openai\";\n   * const openai = new OpenAI();\n   * const response = await openai.generate([\"Tell me a joke.\"]);\n   * ```\n   */\n  async _generate(prompts, options, runManager) {\n    const subPrompts = chunkArray(prompts, this.batchSize);\n    const choices = [];\n    const tokenUsage = {};\n    const params = this.invocationParams(options);\n    if (params.max_tokens === -1) {\n      if (prompts.length !== 1) {\n        throw new Error(\"max_tokens set to -1 not supported for multiple inputs\");\n      }\n      params.max_tokens = await calculateMaxTokens({\n        prompt: prompts[0],\n        // Cast here to allow for other models that may not fit the union\n        modelName: this.modelName\n      });\n    }\n    for (let i = 0; i < subPrompts.length; i += 1) {\n      const data = params.stream ? await (async _options$signal => {\n        const choices = [];\n        let response;\n        const stream = await this.completionWithRetry({\n          ...params,\n          stream: true,\n          prompt: subPrompts[i]\n        }, options);\n        for await (const message of stream) {\n          // on the first message set the response properties\n          if (!response) {\n            response = {\n              id: message.id,\n              object: message.object,\n              created: message.created,\n              model: message.model\n            };\n          }\n          // on all messages, update choice\n          for (const part of message.choices) {\n            if (!choices[part.index]) {\n              choices[part.index] = part;\n            } else {\n              const choice = choices[part.index];\n              choice.text += part.text;\n              choice.finish_reason = part.finish_reason;\n              choice.logprobs = part.logprobs;\n            }\n            void (runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMNewToken(part.text, {\n              prompt: Math.floor(part.index / this.n),\n              completion: part.index % this.n\n            }));\n          }\n        }\n        if ((_options$signal = options.signal) !== null && _options$signal !== void 0 && _options$signal.aborted) {\n          throw new Error(\"AbortError\");\n        }\n        return {\n          ...response,\n          choices\n        };\n      })() : await this.completionWithRetry({\n        ...params,\n        stream: false,\n        prompt: subPrompts[i]\n      }, {\n        signal: options.signal,\n        ...options.options\n      });\n      choices.push(...data.choices);\n      const {\n        completion_tokens: completionTokens,\n        prompt_tokens: promptTokens,\n        total_tokens: totalTokens\n      } = data.usage ? data.usage : {\n        completion_tokens: undefined,\n        prompt_tokens: undefined,\n        total_tokens: undefined\n      };\n      if (completionTokens) {\n        var _tokenUsage$completio;\n        tokenUsage.completionTokens = ((_tokenUsage$completio = tokenUsage.completionTokens) !== null && _tokenUsage$completio !== void 0 ? _tokenUsage$completio : 0) + completionTokens;\n      }\n      if (promptTokens) {\n        var _tokenUsage$promptTok;\n        tokenUsage.promptTokens = ((_tokenUsage$promptTok = tokenUsage.promptTokens) !== null && _tokenUsage$promptTok !== void 0 ? _tokenUsage$promptTok : 0) + promptTokens;\n      }\n      if (totalTokens) {\n        var _tokenUsage$totalToke;\n        tokenUsage.totalTokens = ((_tokenUsage$totalToke = tokenUsage.totalTokens) !== null && _tokenUsage$totalToke !== void 0 ? _tokenUsage$totalToke : 0) + totalTokens;\n      }\n    }\n    const generations = chunkArray(choices, this.n).map(promptChoices => promptChoices.map(choice => {\n      var _choice$text;\n      return {\n        text: (_choice$text = choice.text) !== null && _choice$text !== void 0 ? _choice$text : \"\",\n        generationInfo: {\n          finishReason: choice.finish_reason,\n          logprobs: choice.logprobs\n        }\n      };\n    }));\n    return {\n      generations,\n      llmOutput: {\n        tokenUsage\n      }\n    };\n  }\n  // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation?\n  async *_streamResponseChunks(input, options, runManager) {\n    var _options$signal2;\n    const params = {\n      ...this.invocationParams(options),\n      prompt: input,\n      stream: true\n    };\n    const stream = await this.completionWithRetry(params, options);\n    for await (const data of stream) {\n      var _chunk$text;\n      const choice = data === null || data === void 0 ? void 0 : data.choices[0];\n      if (!choice) {\n        continue;\n      }\n      const chunk = new GenerationChunk({\n        text: choice.text,\n        generationInfo: {\n          finishReason: choice.finish_reason\n        }\n      });\n      yield chunk;\n      // eslint-disable-next-line no-void\n      void (runManager === null || runManager === void 0 ? void 0 : runManager.handleLLMNewToken((_chunk$text = chunk.text) !== null && _chunk$text !== void 0 ? _chunk$text : \"\"));\n    }\n    if ((_options$signal2 = options.signal) !== null && _options$signal2 !== void 0 && _options$signal2.aborted) {\n      throw new Error(\"AbortError\");\n    }\n  }\n  async completionWithRetry(request, options) {\n    const requestOptions = this._getClientOptions(options);\n    return this.caller.call(async () => {\n      try {\n        const res = await this.client.completions.create(request, requestOptions);\n        return res;\n      } catch (e) {\n        const error = wrapOpenAIClientError(e);\n        throw error;\n      }\n    });\n  }\n  /**\n   * Calls the OpenAI API with retry logic in case of failures.\n   * @param request The request to send to the OpenAI API.\n   * @param options Optional configuration for the API call.\n   * @returns The response from the OpenAI API.\n   */\n  _getClientOptions(options) {\n    if (!this.client) {\n      const openAIEndpointConfig = {\n        azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n        azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n        azureOpenAIApiKey: this.azureOpenAIApiKey,\n        azureOpenAIBasePath: this.azureOpenAIBasePath,\n        baseURL: this.clientConfig.baseURL\n      };\n      const endpoint = getEndpoint(openAIEndpointConfig);\n      const params = {\n        ...this.clientConfig,\n        baseURL: endpoint,\n        timeout: this.timeout,\n        maxRetries: 0\n      };\n      if (!params.baseURL) {\n        delete params.baseURL;\n      }\n      this.client = new OpenAIClient(params);\n    }\n    const requestOptions = {\n      ...this.clientConfig,\n      ...options\n    };\n    if (this.azureOpenAIApiKey) {\n      requestOptions.headers = {\n        \"api-key\": this.azureOpenAIApiKey,\n        ...requestOptions.headers\n      };\n      requestOptions.query = {\n        \"api-version\": this.azureOpenAIApiVersion,\n        ...requestOptions.query\n      };\n    }\n    return requestOptions;\n  }\n  _llmType() {\n    return \"openai\";\n  }\n}","map":{"version":3,"names":["OpenAI","OpenAIClient","calculateMaxTokens","GenerationChunk","getEnvironmentVariable","BaseLLM","chunkArray","getEndpoint","OpenAIChat","wrapOpenAIClientError","lc_name","callKeys","lc_secrets","openAIApiKey","azureOpenAIApiKey","organization","lc_aliases","modelName","azureOpenAIApiVersion","azureOpenAIApiInstanceName","azureOpenAIApiDeploymentName","constructor","fields","configuration","_fields$modelName","_fields$modelName2","_fields$modelName3","_fields$openAIApiKey","_fields$azureOpenAIAp","_fields$azureOpenAIAp2","_ref","_fields$azureOpenAIAp3","_fields$azureOpenAIBa","_fields$configuration","_fields$configuration2","_fields$modelName4","_fields$modelKwargs","_fields$batchSize","_fields$temperature","_fields$maxTokens","_fields$topP","_fields$frequencyPena","_fields$presencePenal","_fields$n","_fields$bestOf","_fields$streaming","_configuration$basePa","_fields$configuration3","_configuration$baseOp","_configuration$baseOp2","_fields$configuration4","_configuration$baseOp3","_configuration$baseOp4","_fields$configuration5","startsWith","includes","Object","defineProperty","enumerable","configurable","writable","value","Error","azureOpenAIApiCompletionsDeploymentName","azureOpenAIBasePath","modelKwargs","batchSize","timeout","temperature","maxTokens","topP","frequencyPenalty","presencePenalty","n","bestOf","logitBias","stop","user","streaming","_this$openAIApiKey","clientConfig","apiKey","baseURL","basePath","dangerouslyAllowBrowser","defaultHeaders","baseOptions","headers","defaultQuery","params","invocationParams","options","_options$stop","model","max_tokens","top_p","frequency_penalty","presence_penalty","best_of","logit_bias","stream","_identifyingParams","model_name","identifyingParams","_generate","prompts","runManager","subPrompts","choices","tokenUsage","length","prompt","i","data","_options$signal","response","completionWithRetry","message","id","object","created","part","index","choice","text","finish_reason","logprobs","handleLLMNewToken","Math","floor","completion","signal","aborted","push","completion_tokens","completionTokens","prompt_tokens","promptTokens","total_tokens","totalTokens","usage","undefined","_tokenUsage$completio","_tokenUsage$promptTok","_tokenUsage$totalToke","generations","map","promptChoices","_choice$text","generationInfo","finishReason","llmOutput","_streamResponseChunks","input","_options$signal2","_chunk$text","chunk","request","requestOptions","_getClientOptions","caller","call","res","client","completions","create","e","error","openAIEndpointConfig","endpoint","maxRetries","query","_llmType"],"sources":["/Users/mandylin/Desktop/WebCrack React/webcrack/node_modules/@langchain/openai/dist/llms.js"],"sourcesContent":["import { OpenAI as OpenAIClient } from \"openai\";\nimport { calculateMaxTokens } from \"@langchain/core/language_models/base\";\nimport { GenerationChunk } from \"@langchain/core/outputs\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { BaseLLM, } from \"@langchain/core/language_models/llms\";\nimport { chunkArray } from \"@langchain/core/utils/chunk_array\";\nimport { getEndpoint } from \"./utils/azure.js\";\nimport { OpenAIChat } from \"./legacy.js\";\nimport { wrapOpenAIClientError } from \"./utils/openai.js\";\nexport { OpenAIChat };\n/**\n * Wrapper around OpenAI large language models.\n *\n * To use you should have the `openai` package installed, with the\n * `OPENAI_API_KEY` environment variable set.\n *\n * To use with Azure you should have the `openai` package installed, with the\n * `AZURE_OPENAI_API_KEY`,\n * `AZURE_OPENAI_API_INSTANCE_NAME`,\n * `AZURE_OPENAI_API_DEPLOYMENT_NAME`\n * and `AZURE_OPENAI_API_VERSION` environment variable set.\n *\n * @remarks\n * Any parameters that are valid to be passed to {@link\n * https://platform.openai.com/docs/api-reference/completions/create |\n * `openai.createCompletion`} can be passed through {@link modelKwargs}, even\n * if not explicitly available on this class.\n * @example\n * ```typescript\n * const model = new OpenAI({\n *   modelName: \"gpt-4\",\n *   temperature: 0.7,\n *   maxTokens: 1000,\n *   maxRetries: 5,\n * });\n *\n * const res = await model.call(\n *   \"Question: What would be a good company name for a company that makes colorful socks?\\nAnswer:\"\n * );\n * console.log({ res });\n * ```\n */\nexport class OpenAI extends BaseLLM {\n    static lc_name() {\n        return \"OpenAI\";\n    }\n    get callKeys() {\n        return [...super.callKeys, \"options\"];\n    }\n    get lc_secrets() {\n        return {\n            openAIApiKey: \"OPENAI_API_KEY\",\n            azureOpenAIApiKey: \"AZURE_OPENAI_API_KEY\",\n            organization: \"OPENAI_ORGANIZATION\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            modelName: \"model\",\n            openAIApiKey: \"openai_api_key\",\n            azureOpenAIApiVersion: \"azure_openai_api_version\",\n            azureOpenAIApiKey: \"azure_openai_api_key\",\n            azureOpenAIApiInstanceName: \"azure_openai_api_instance_name\",\n            azureOpenAIApiDeploymentName: \"azure_openai_api_deployment_name\",\n        };\n    }\n    constructor(fields, \n    /** @deprecated */\n    configuration) {\n        if ((fields?.modelName?.startsWith(\"gpt-3.5-turbo\") ||\n            fields?.modelName?.startsWith(\"gpt-4\")) &&\n            !fields?.modelName?.includes(\"-instruct\")) {\n            // eslint-disable-next-line no-constructor-return\n            return new OpenAIChat(fields, configuration);\n        }\n        super(fields ?? {});\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0.7\n        });\n        Object.defineProperty(this, \"maxTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 256\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"frequencyPenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"presencePenalty\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 0\n        });\n        Object.defineProperty(this, \"n\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1\n        });\n        Object.defineProperty(this, \"bestOf\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"logitBias\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"gpt-3.5-turbo-instruct\"\n        });\n        Object.defineProperty(this, \"modelKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"batchSize\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 20\n        });\n        Object.defineProperty(this, \"timeout\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stop\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"user\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"openAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiVersion\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiInstanceName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIApiDeploymentName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"azureOpenAIBasePath\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"organization\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"clientConfig\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.openAIApiKey =\n            fields?.openAIApiKey ?? getEnvironmentVariable(\"OPENAI_API_KEY\");\n        this.azureOpenAIApiKey =\n            fields?.azureOpenAIApiKey ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_KEY\");\n        if (!this.azureOpenAIApiKey && !this.openAIApiKey) {\n            throw new Error(\"OpenAI or Azure OpenAI API key not found\");\n        }\n        this.azureOpenAIApiInstanceName =\n            fields?.azureOpenAIApiInstanceName ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_INSTANCE_NAME\");\n        this.azureOpenAIApiDeploymentName =\n            (fields?.azureOpenAIApiCompletionsDeploymentName ||\n                fields?.azureOpenAIApiDeploymentName) ??\n                (getEnvironmentVariable(\"AZURE_OPENAI_API_COMPLETIONS_DEPLOYMENT_NAME\") ||\n                    getEnvironmentVariable(\"AZURE_OPENAI_API_DEPLOYMENT_NAME\"));\n        this.azureOpenAIApiVersion =\n            fields?.azureOpenAIApiVersion ??\n                getEnvironmentVariable(\"AZURE_OPENAI_API_VERSION\");\n        this.azureOpenAIBasePath =\n            fields?.azureOpenAIBasePath ??\n                getEnvironmentVariable(\"AZURE_OPENAI_BASE_PATH\");\n        this.organization =\n            fields?.configuration?.organization ??\n                getEnvironmentVariable(\"OPENAI_ORGANIZATION\");\n        this.modelName = fields?.modelName ?? this.modelName;\n        this.modelKwargs = fields?.modelKwargs ?? {};\n        this.batchSize = fields?.batchSize ?? this.batchSize;\n        this.timeout = fields?.timeout;\n        this.temperature = fields?.temperature ?? this.temperature;\n        this.maxTokens = fields?.maxTokens ?? this.maxTokens;\n        this.topP = fields?.topP ?? this.topP;\n        this.frequencyPenalty = fields?.frequencyPenalty ?? this.frequencyPenalty;\n        this.presencePenalty = fields?.presencePenalty ?? this.presencePenalty;\n        this.n = fields?.n ?? this.n;\n        this.bestOf = fields?.bestOf ?? this.bestOf;\n        this.logitBias = fields?.logitBias;\n        this.stop = fields?.stop;\n        this.user = fields?.user;\n        this.streaming = fields?.streaming ?? false;\n        if (this.streaming && this.bestOf && this.bestOf > 1) {\n            throw new Error(\"Cannot stream results when bestOf > 1\");\n        }\n        if (this.azureOpenAIApiKey) {\n            if (!this.azureOpenAIApiInstanceName && !this.azureOpenAIBasePath) {\n                throw new Error(\"Azure OpenAI API instance name not found\");\n            }\n            if (!this.azureOpenAIApiDeploymentName) {\n                throw new Error(\"Azure OpenAI API deployment name not found\");\n            }\n            if (!this.azureOpenAIApiVersion) {\n                throw new Error(\"Azure OpenAI API version not found\");\n            }\n            this.openAIApiKey = this.openAIApiKey ?? \"\";\n        }\n        this.clientConfig = {\n            apiKey: this.openAIApiKey,\n            organization: this.organization,\n            baseURL: configuration?.basePath ?? fields?.configuration?.basePath,\n            dangerouslyAllowBrowser: true,\n            defaultHeaders: configuration?.baseOptions?.headers ??\n                fields?.configuration?.baseOptions?.headers,\n            defaultQuery: configuration?.baseOptions?.params ??\n                fields?.configuration?.baseOptions?.params,\n            ...configuration,\n            ...fields?.configuration,\n        };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    invocationParams(options) {\n        return {\n            model: this.modelName,\n            temperature: this.temperature,\n            max_tokens: this.maxTokens,\n            top_p: this.topP,\n            frequency_penalty: this.frequencyPenalty,\n            presence_penalty: this.presencePenalty,\n            n: this.n,\n            best_of: this.bestOf,\n            logit_bias: this.logitBias,\n            stop: options?.stop ?? this.stop,\n            user: this.user,\n            stream: this.streaming,\n            ...this.modelKwargs,\n        };\n    }\n    /** @ignore */\n    _identifyingParams() {\n        return {\n            model_name: this.modelName,\n            ...this.invocationParams(),\n            ...this.clientConfig,\n        };\n    }\n    /**\n     * Get the identifying parameters for the model\n     */\n    identifyingParams() {\n        return this._identifyingParams();\n    }\n    /**\n     * Call out to OpenAI's endpoint with k unique prompts\n     *\n     * @param [prompts] - The prompts to pass into the model.\n     * @param [options] - Optional list of stop words to use when generating.\n     * @param [runManager] - Optional callback manager to use when generating.\n     *\n     * @returns The full LLM output.\n     *\n     * @example\n     * ```ts\n     * import { OpenAI } from \"langchain/llms/openai\";\n     * const openai = new OpenAI();\n     * const response = await openai.generate([\"Tell me a joke.\"]);\n     * ```\n     */\n    async _generate(prompts, options, runManager) {\n        const subPrompts = chunkArray(prompts, this.batchSize);\n        const choices = [];\n        const tokenUsage = {};\n        const params = this.invocationParams(options);\n        if (params.max_tokens === -1) {\n            if (prompts.length !== 1) {\n                throw new Error(\"max_tokens set to -1 not supported for multiple inputs\");\n            }\n            params.max_tokens = await calculateMaxTokens({\n                prompt: prompts[0],\n                // Cast here to allow for other models that may not fit the union\n                modelName: this.modelName,\n            });\n        }\n        for (let i = 0; i < subPrompts.length; i += 1) {\n            const data = params.stream\n                ? await (async () => {\n                    const choices = [];\n                    let response;\n                    const stream = await this.completionWithRetry({\n                        ...params,\n                        stream: true,\n                        prompt: subPrompts[i],\n                    }, options);\n                    for await (const message of stream) {\n                        // on the first message set the response properties\n                        if (!response) {\n                            response = {\n                                id: message.id,\n                                object: message.object,\n                                created: message.created,\n                                model: message.model,\n                            };\n                        }\n                        // on all messages, update choice\n                        for (const part of message.choices) {\n                            if (!choices[part.index]) {\n                                choices[part.index] = part;\n                            }\n                            else {\n                                const choice = choices[part.index];\n                                choice.text += part.text;\n                                choice.finish_reason = part.finish_reason;\n                                choice.logprobs = part.logprobs;\n                            }\n                            void runManager?.handleLLMNewToken(part.text, {\n                                prompt: Math.floor(part.index / this.n),\n                                completion: part.index % this.n,\n                            });\n                        }\n                    }\n                    if (options.signal?.aborted) {\n                        throw new Error(\"AbortError\");\n                    }\n                    return { ...response, choices };\n                })()\n                : await this.completionWithRetry({\n                    ...params,\n                    stream: false,\n                    prompt: subPrompts[i],\n                }, {\n                    signal: options.signal,\n                    ...options.options,\n                });\n            choices.push(...data.choices);\n            const { completion_tokens: completionTokens, prompt_tokens: promptTokens, total_tokens: totalTokens, } = data.usage\n                ? data.usage\n                : {\n                    completion_tokens: undefined,\n                    prompt_tokens: undefined,\n                    total_tokens: undefined,\n                };\n            if (completionTokens) {\n                tokenUsage.completionTokens =\n                    (tokenUsage.completionTokens ?? 0) + completionTokens;\n            }\n            if (promptTokens) {\n                tokenUsage.promptTokens = (tokenUsage.promptTokens ?? 0) + promptTokens;\n            }\n            if (totalTokens) {\n                tokenUsage.totalTokens = (tokenUsage.totalTokens ?? 0) + totalTokens;\n            }\n        }\n        const generations = chunkArray(choices, this.n).map((promptChoices) => promptChoices.map((choice) => ({\n            text: choice.text ?? \"\",\n            generationInfo: {\n                finishReason: choice.finish_reason,\n                logprobs: choice.logprobs,\n            },\n        })));\n        return {\n            generations,\n            llmOutput: { tokenUsage },\n        };\n    }\n    // TODO(jacoblee): Refactor with _generate(..., {stream: true}) implementation?\n    async *_streamResponseChunks(input, options, runManager) {\n        const params = {\n            ...this.invocationParams(options),\n            prompt: input,\n            stream: true,\n        };\n        const stream = await this.completionWithRetry(params, options);\n        for await (const data of stream) {\n            const choice = data?.choices[0];\n            if (!choice) {\n                continue;\n            }\n            const chunk = new GenerationChunk({\n                text: choice.text,\n                generationInfo: {\n                    finishReason: choice.finish_reason,\n                },\n            });\n            yield chunk;\n            // eslint-disable-next-line no-void\n            void runManager?.handleLLMNewToken(chunk.text ?? \"\");\n        }\n        if (options.signal?.aborted) {\n            throw new Error(\"AbortError\");\n        }\n    }\n    async completionWithRetry(request, options) {\n        const requestOptions = this._getClientOptions(options);\n        return this.caller.call(async () => {\n            try {\n                const res = await this.client.completions.create(request, requestOptions);\n                return res;\n            }\n            catch (e) {\n                const error = wrapOpenAIClientError(e);\n                throw error;\n            }\n        });\n    }\n    /**\n     * Calls the OpenAI API with retry logic in case of failures.\n     * @param request The request to send to the OpenAI API.\n     * @param options Optional configuration for the API call.\n     * @returns The response from the OpenAI API.\n     */\n    _getClientOptions(options) {\n        if (!this.client) {\n            const openAIEndpointConfig = {\n                azureOpenAIApiDeploymentName: this.azureOpenAIApiDeploymentName,\n                azureOpenAIApiInstanceName: this.azureOpenAIApiInstanceName,\n                azureOpenAIApiKey: this.azureOpenAIApiKey,\n                azureOpenAIBasePath: this.azureOpenAIBasePath,\n                baseURL: this.clientConfig.baseURL,\n            };\n            const endpoint = getEndpoint(openAIEndpointConfig);\n            const params = {\n                ...this.clientConfig,\n                baseURL: endpoint,\n                timeout: this.timeout,\n                maxRetries: 0,\n            };\n            if (!params.baseURL) {\n                delete params.baseURL;\n            }\n            this.client = new OpenAIClient(params);\n        }\n        const requestOptions = {\n            ...this.clientConfig,\n            ...options,\n        };\n        if (this.azureOpenAIApiKey) {\n            requestOptions.headers = {\n                \"api-key\": this.azureOpenAIApiKey,\n                ...requestOptions.headers,\n            };\n            requestOptions.query = {\n                \"api-version\": this.azureOpenAIApiVersion,\n                ...requestOptions.query,\n            };\n        }\n        return requestOptions;\n    }\n    _llmType() {\n        return \"openai\";\n    }\n}\n"],"mappings":"AAAA,SAASA,MAAM,IAAIC,YAAY,QAAQ,QAAQ;AAC/C,SAASC,kBAAkB,QAAQ,sCAAsC;AACzE,SAASC,eAAe,QAAQ,yBAAyB;AACzD,SAASC,sBAAsB,QAAQ,2BAA2B;AAClE,SAASC,OAAO,QAAS,sCAAsC;AAC/D,SAASC,UAAU,QAAQ,mCAAmC;AAC9D,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,SAASC,UAAU,QAAQ,aAAa;AACxC,SAASC,qBAAqB,QAAQ,mBAAmB;AACzD,SAASD,UAAU;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMR,MAAM,SAASK,OAAO,CAAC;EAChC,OAAOK,OAAOA,CAAA,EAAG;IACb,OAAO,QAAQ;EACnB;EACA,IAAIC,QAAQA,CAAA,EAAG;IACX,OAAO,CAAC,GAAG,KAAK,CAACA,QAAQ,EAAE,SAAS,CAAC;EACzC;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,YAAY,EAAE,gBAAgB;MAC9BC,iBAAiB,EAAE,sBAAsB;MACzCC,YAAY,EAAE;IAClB,CAAC;EACL;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO;MACHC,SAAS,EAAE,OAAO;MAClBJ,YAAY,EAAE,gBAAgB;MAC9BK,qBAAqB,EAAE,0BAA0B;MACjDJ,iBAAiB,EAAE,sBAAsB;MACzCK,0BAA0B,EAAE,gCAAgC;MAC5DC,4BAA4B,EAAE;IAClC,CAAC;EACL;EACAC,WAAWA,CAACC,MAAM,EAClB;EACAC,aAAa,EAAE;IAAA,IAAAC,iBAAA,EAAAC,kBAAA,EAAAC,kBAAA,EAAAC,oBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,IAAA,EAAAC,sBAAA,EAAAC,qBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,kBAAA,EAAAC,mBAAA,EAAAC,iBAAA,EAAAC,mBAAA,EAAAC,iBAAA,EAAAC,YAAA,EAAAC,qBAAA,EAAAC,qBAAA,EAAAC,SAAA,EAAAC,cAAA,EAAAC,iBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,qBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA;IACX,IAAI,CAAC/B,MAAM,aAANA,MAAM,gBAAAE,iBAAA,GAANF,MAAM,CAAEL,SAAS,cAAAO,iBAAA,eAAjBA,iBAAA,CAAmB8B,UAAU,CAAC,eAAe,CAAC,IAC/ChC,MAAM,aAANA,MAAM,gBAAAG,kBAAA,GAANH,MAAM,CAAEL,SAAS,cAAAQ,kBAAA,eAAjBA,kBAAA,CAAmB6B,UAAU,CAAC,OAAO,CAAC,KACtC,EAAChC,MAAM,aAANA,MAAM,gBAAAI,kBAAA,GAANJ,MAAM,CAAEL,SAAS,cAAAS,kBAAA,eAAjBA,kBAAA,CAAmB6B,QAAQ,CAAC,WAAW,CAAC,GAAE;MAC3C;MACA,OAAO,IAAI/C,UAAU,CAACc,MAAM,EAAEC,aAAa,CAAC;IAChD;IACA,KAAK,CAACD,MAAM,aAANA,MAAM,cAANA,MAAM,GAAI,CAAC,CAAC,CAAC;IACnBkC,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,kBAAkB,EAAE;MAC5CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,GAAG,EAAE;MAC7BC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,aAAa,EAAE;MACvCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,SAAS,EAAE;MACnCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,MAAM,EAAE;MAChCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,mBAAmB,EAAE;MAC7CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,4BAA4B,EAAE;MACtDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,8BAA8B,EAAE;MACxDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,qBAAqB,EAAE;MAC/CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAAChD,YAAY,IAAAc,oBAAA,GACbL,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAET,YAAY,cAAAc,oBAAA,cAAAA,oBAAA,GAAIvB,sBAAsB,CAAC,gBAAgB,CAAC;IACpE,IAAI,CAACU,iBAAiB,IAAAc,qBAAA,GAClBN,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAER,iBAAiB,cAAAc,qBAAA,cAAAA,qBAAA,GACrBxB,sBAAsB,CAAC,sBAAsB,CAAC;IACtD,IAAI,CAAC,IAAI,CAACU,iBAAiB,IAAI,CAAC,IAAI,CAACD,YAAY,EAAE;MAC/C,MAAM,IAAIiD,KAAK,CAAC,0CAA0C,CAAC;IAC/D;IACA,IAAI,CAAC3C,0BAA0B,IAAAU,sBAAA,GAC3BP,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEH,0BAA0B,cAAAU,sBAAA,cAAAA,sBAAA,GAC9BzB,sBAAsB,CAAC,gCAAgC,CAAC;IAChE,IAAI,CAACgB,4BAA4B,IAAAU,IAAA,GAC5B,CAAAR,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEyC,uCAAuC,MAC5CzC,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEF,4BAA4B,eAAAU,IAAA,cAAAA,IAAA,GACnC1B,sBAAsB,CAAC,8CAA8C,CAAC,IACnEA,sBAAsB,CAAC,kCAAkC,CAAE;IACvE,IAAI,CAACc,qBAAqB,IAAAa,sBAAA,GACtBT,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEJ,qBAAqB,cAAAa,sBAAA,cAAAA,sBAAA,GACzB3B,sBAAsB,CAAC,0BAA0B,CAAC;IAC1D,IAAI,CAAC4D,mBAAmB,IAAAhC,qBAAA,GACpBV,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE0C,mBAAmB,cAAAhC,qBAAA,cAAAA,qBAAA,GACvB5B,sBAAsB,CAAC,wBAAwB,CAAC;IACxD,IAAI,CAACW,YAAY,IAAAkB,qBAAA,GACbX,MAAM,aAANA,MAAM,gBAAAY,sBAAA,GAANZ,MAAM,CAAEC,aAAa,cAAAW,sBAAA,uBAArBA,sBAAA,CAAuBnB,YAAY,cAAAkB,qBAAA,cAAAA,qBAAA,GAC/B7B,sBAAsB,CAAC,qBAAqB,CAAC;IACrD,IAAI,CAACa,SAAS,IAAAkB,kBAAA,GAAGb,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEL,SAAS,cAAAkB,kBAAA,cAAAA,kBAAA,GAAI,IAAI,CAAClB,SAAS;IACpD,IAAI,CAACgD,WAAW,IAAA7B,mBAAA,GAAGd,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE2C,WAAW,cAAA7B,mBAAA,cAAAA,mBAAA,GAAI,CAAC,CAAC;IAC5C,IAAI,CAAC8B,SAAS,IAAA7B,iBAAA,GAAGf,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE4C,SAAS,cAAA7B,iBAAA,cAAAA,iBAAA,GAAI,IAAI,CAAC6B,SAAS;IACpD,IAAI,CAACC,OAAO,GAAG7C,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE6C,OAAO;IAC9B,IAAI,CAACC,WAAW,IAAA9B,mBAAA,GAAGhB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE8C,WAAW,cAAA9B,mBAAA,cAAAA,mBAAA,GAAI,IAAI,CAAC8B,WAAW;IAC1D,IAAI,CAACC,SAAS,IAAA9B,iBAAA,GAAGjB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAE+C,SAAS,cAAA9B,iBAAA,cAAAA,iBAAA,GAAI,IAAI,CAAC8B,SAAS;IACpD,IAAI,CAACC,IAAI,IAAA9B,YAAA,GAAGlB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEgD,IAAI,cAAA9B,YAAA,cAAAA,YAAA,GAAI,IAAI,CAAC8B,IAAI;IACrC,IAAI,CAACC,gBAAgB,IAAA9B,qBAAA,GAAGnB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEiD,gBAAgB,cAAA9B,qBAAA,cAAAA,qBAAA,GAAI,IAAI,CAAC8B,gBAAgB;IACzE,IAAI,CAACC,eAAe,IAAA9B,qBAAA,GAAGpB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEkD,eAAe,cAAA9B,qBAAA,cAAAA,qBAAA,GAAI,IAAI,CAAC8B,eAAe;IACtE,IAAI,CAACC,CAAC,IAAA9B,SAAA,GAAGrB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEmD,CAAC,cAAA9B,SAAA,cAAAA,SAAA,GAAI,IAAI,CAAC8B,CAAC;IAC5B,IAAI,CAACC,MAAM,IAAA9B,cAAA,GAAGtB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEoD,MAAM,cAAA9B,cAAA,cAAAA,cAAA,GAAI,IAAI,CAAC8B,MAAM;IAC3C,IAAI,CAACC,SAAS,GAAGrD,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEqD,SAAS;IAClC,IAAI,CAACC,IAAI,GAAGtD,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEsD,IAAI;IACxB,IAAI,CAACC,IAAI,GAAGvD,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEuD,IAAI;IACxB,IAAI,CAACC,SAAS,IAAAjC,iBAAA,GAAGvB,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEwD,SAAS,cAAAjC,iBAAA,cAAAA,iBAAA,GAAI,KAAK;IAC3C,IAAI,IAAI,CAACiC,SAAS,IAAI,IAAI,CAACJ,MAAM,IAAI,IAAI,CAACA,MAAM,GAAG,CAAC,EAAE;MAClD,MAAM,IAAIZ,KAAK,CAAC,uCAAuC,CAAC;IAC5D;IACA,IAAI,IAAI,CAAChD,iBAAiB,EAAE;MAAA,IAAAiE,kBAAA;MACxB,IAAI,CAAC,IAAI,CAAC5D,0BAA0B,IAAI,CAAC,IAAI,CAAC6C,mBAAmB,EAAE;QAC/D,MAAM,IAAIF,KAAK,CAAC,0CAA0C,CAAC;MAC/D;MACA,IAAI,CAAC,IAAI,CAAC1C,4BAA4B,EAAE;QACpC,MAAM,IAAI0C,KAAK,CAAC,4CAA4C,CAAC;MACjE;MACA,IAAI,CAAC,IAAI,CAAC5C,qBAAqB,EAAE;QAC7B,MAAM,IAAI4C,KAAK,CAAC,oCAAoC,CAAC;MACzD;MACA,IAAI,CAACjD,YAAY,IAAAkE,kBAAA,GAAG,IAAI,CAAClE,YAAY,cAAAkE,kBAAA,cAAAA,kBAAA,GAAI,EAAE;IAC/C;IACA,IAAI,CAACC,YAAY,GAAG;MAChBC,MAAM,EAAE,IAAI,CAACpE,YAAY;MACzBE,YAAY,EAAE,IAAI,CAACA,YAAY;MAC/BmE,OAAO,GAAApC,qBAAA,GAAEvB,aAAa,aAAbA,aAAa,uBAAbA,aAAa,CAAE4D,QAAQ,cAAArC,qBAAA,cAAAA,qBAAA,GAAIxB,MAAM,aAANA,MAAM,gBAAAyB,sBAAA,GAANzB,MAAM,CAAEC,aAAa,cAAAwB,sBAAA,uBAArBA,sBAAA,CAAuBoC,QAAQ;MACnEC,uBAAuB,EAAE,IAAI;MAC7BC,cAAc,GAAArC,qBAAA,GAAEzB,aAAa,aAAbA,aAAa,gBAAA0B,sBAAA,GAAb1B,aAAa,CAAE+D,WAAW,cAAArC,sBAAA,uBAA1BA,sBAAA,CAA4BsC,OAAO,cAAAvC,qBAAA,cAAAA,qBAAA,GAC/C1B,MAAM,aAANA,MAAM,gBAAA4B,sBAAA,GAAN5B,MAAM,CAAEC,aAAa,cAAA2B,sBAAA,gBAAAA,sBAAA,GAArBA,sBAAA,CAAuBoC,WAAW,cAAApC,sBAAA,uBAAlCA,sBAAA,CAAoCqC,OAAO;MAC/CC,YAAY,GAAArC,sBAAA,GAAE5B,aAAa,aAAbA,aAAa,gBAAA6B,sBAAA,GAAb7B,aAAa,CAAE+D,WAAW,cAAAlC,sBAAA,uBAA1BA,sBAAA,CAA4BqC,MAAM,cAAAtC,sBAAA,cAAAA,sBAAA,GAC5C7B,MAAM,aAANA,MAAM,gBAAA+B,sBAAA,GAAN/B,MAAM,CAAEC,aAAa,cAAA8B,sBAAA,gBAAAA,sBAAA,GAArBA,sBAAA,CAAuBiC,WAAW,cAAAjC,sBAAA,uBAAlCA,sBAAA,CAAoCoC,MAAM;MAC9C,GAAGlE,aAAa;MAChB,IAAGD,MAAM,aAANA,MAAM,uBAANA,MAAM,CAAEC,aAAa;IAC5B,CAAC;EACL;EACA;AACJ;AACA;EACImE,gBAAgBA,CAACC,OAAO,EAAE;IAAA,IAAAC,aAAA;IACtB,OAAO;MACHC,KAAK,EAAE,IAAI,CAAC5E,SAAS;MACrBmD,WAAW,EAAE,IAAI,CAACA,WAAW;MAC7B0B,UAAU,EAAE,IAAI,CAACzB,SAAS;MAC1B0B,KAAK,EAAE,IAAI,CAACzB,IAAI;MAChB0B,iBAAiB,EAAE,IAAI,CAACzB,gBAAgB;MACxC0B,gBAAgB,EAAE,IAAI,CAACzB,eAAe;MACtCC,CAAC,EAAE,IAAI,CAACA,CAAC;MACTyB,OAAO,EAAE,IAAI,CAACxB,MAAM;MACpByB,UAAU,EAAE,IAAI,CAACxB,SAAS;MAC1BC,IAAI,GAAAgB,aAAA,GAAED,OAAO,aAAPA,OAAO,uBAAPA,OAAO,CAAEf,IAAI,cAAAgB,aAAA,cAAAA,aAAA,GAAI,IAAI,CAAChB,IAAI;MAChCC,IAAI,EAAE,IAAI,CAACA,IAAI;MACfuB,MAAM,EAAE,IAAI,CAACtB,SAAS;MACtB,GAAG,IAAI,CAACb;IACZ,CAAC;EACL;EACA;EACAoC,kBAAkBA,CAAA,EAAG;IACjB,OAAO;MACHC,UAAU,EAAE,IAAI,CAACrF,SAAS;MAC1B,GAAG,IAAI,CAACyE,gBAAgB,CAAC,CAAC;MAC1B,GAAG,IAAI,CAACV;IACZ,CAAC;EACL;EACA;AACJ;AACA;EACIuB,iBAAiBA,CAAA,EAAG;IAChB,OAAO,IAAI,CAACF,kBAAkB,CAAC,CAAC;EACpC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMG,SAASA,CAACC,OAAO,EAAEd,OAAO,EAAEe,UAAU,EAAE;IAC1C,MAAMC,UAAU,GAAGrG,UAAU,CAACmG,OAAO,EAAE,IAAI,CAACvC,SAAS,CAAC;IACtD,MAAM0C,OAAO,GAAG,EAAE;IAClB,MAAMC,UAAU,GAAG,CAAC,CAAC;IACrB,MAAMpB,MAAM,GAAG,IAAI,CAACC,gBAAgB,CAACC,OAAO,CAAC;IAC7C,IAAIF,MAAM,CAACK,UAAU,KAAK,CAAC,CAAC,EAAE;MAC1B,IAAIW,OAAO,CAACK,MAAM,KAAK,CAAC,EAAE;QACtB,MAAM,IAAIhD,KAAK,CAAC,wDAAwD,CAAC;MAC7E;MACA2B,MAAM,CAACK,UAAU,GAAG,MAAM5F,kBAAkB,CAAC;QACzC6G,MAAM,EAAEN,OAAO,CAAC,CAAC,CAAC;QAClB;QACAxF,SAAS,EAAE,IAAI,CAACA;MACpB,CAAC,CAAC;IACN;IACA,KAAK,IAAI+F,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGL,UAAU,CAACG,MAAM,EAAEE,CAAC,IAAI,CAAC,EAAE;MAC3C,MAAMC,IAAI,GAAGxB,MAAM,CAACW,MAAM,GACpB,MAAM,CAAC,MAAAc,eAAA,IAAY;QACjB,MAAMN,OAAO,GAAG,EAAE;QAClB,IAAIO,QAAQ;QACZ,MAAMf,MAAM,GAAG,MAAM,IAAI,CAACgB,mBAAmB,CAAC;UAC1C,GAAG3B,MAAM;UACTW,MAAM,EAAE,IAAI;UACZW,MAAM,EAAEJ,UAAU,CAACK,CAAC;QACxB,CAAC,EAAErB,OAAO,CAAC;QACX,WAAW,MAAM0B,OAAO,IAAIjB,MAAM,EAAE;UAChC;UACA,IAAI,CAACe,QAAQ,EAAE;YACXA,QAAQ,GAAG;cACPG,EAAE,EAAED,OAAO,CAACC,EAAE;cACdC,MAAM,EAAEF,OAAO,CAACE,MAAM;cACtBC,OAAO,EAAEH,OAAO,CAACG,OAAO;cACxB3B,KAAK,EAAEwB,OAAO,CAACxB;YACnB,CAAC;UACL;UACA;UACA,KAAK,MAAM4B,IAAI,IAAIJ,OAAO,CAACT,OAAO,EAAE;YAChC,IAAI,CAACA,OAAO,CAACa,IAAI,CAACC,KAAK,CAAC,EAAE;cACtBd,OAAO,CAACa,IAAI,CAACC,KAAK,CAAC,GAAGD,IAAI;YAC9B,CAAC,MACI;cACD,MAAME,MAAM,GAAGf,OAAO,CAACa,IAAI,CAACC,KAAK,CAAC;cAClCC,MAAM,CAACC,IAAI,IAAIH,IAAI,CAACG,IAAI;cACxBD,MAAM,CAACE,aAAa,GAAGJ,IAAI,CAACI,aAAa;cACzCF,MAAM,CAACG,QAAQ,GAAGL,IAAI,CAACK,QAAQ;YACnC;YACA,MAAKpB,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEqB,iBAAiB,CAACN,IAAI,CAACG,IAAI,EAAE;cAC1Cb,MAAM,EAAEiB,IAAI,CAACC,KAAK,CAACR,IAAI,CAACC,KAAK,GAAG,IAAI,CAACjD,CAAC,CAAC;cACvCyD,UAAU,EAAET,IAAI,CAACC,KAAK,GAAG,IAAI,CAACjD;YAClC,CAAC,CAAC;UACN;QACJ;QACA,KAAAyC,eAAA,GAAIvB,OAAO,CAACwC,MAAM,cAAAjB,eAAA,eAAdA,eAAA,CAAgBkB,OAAO,EAAE;UACzB,MAAM,IAAItE,KAAK,CAAC,YAAY,CAAC;QACjC;QACA,OAAO;UAAE,GAAGqD,QAAQ;UAAEP;QAAQ,CAAC;MACnC,CAAC,EAAE,CAAC,GACF,MAAM,IAAI,CAACQ,mBAAmB,CAAC;QAC7B,GAAG3B,MAAM;QACTW,MAAM,EAAE,KAAK;QACbW,MAAM,EAAEJ,UAAU,CAACK,CAAC;MACxB,CAAC,EAAE;QACCmB,MAAM,EAAExC,OAAO,CAACwC,MAAM;QACtB,GAAGxC,OAAO,CAACA;MACf,CAAC,CAAC;MACNiB,OAAO,CAACyB,IAAI,CAAC,GAAGpB,IAAI,CAACL,OAAO,CAAC;MAC7B,MAAM;QAAE0B,iBAAiB,EAAEC,gBAAgB;QAAEC,aAAa,EAAEC,YAAY;QAAEC,YAAY,EAAEC;MAAa,CAAC,GAAG1B,IAAI,CAAC2B,KAAK,GAC7G3B,IAAI,CAAC2B,KAAK,GACV;QACEN,iBAAiB,EAAEO,SAAS;QAC5BL,aAAa,EAAEK,SAAS;QACxBH,YAAY,EAAEG;MAClB,CAAC;MACL,IAAIN,gBAAgB,EAAE;QAAA,IAAAO,qBAAA;QAClBjC,UAAU,CAAC0B,gBAAgB,GACvB,EAAAO,qBAAA,GAACjC,UAAU,CAAC0B,gBAAgB,cAAAO,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIP,gBAAgB;MAC7D;MACA,IAAIE,YAAY,EAAE;QAAA,IAAAM,qBAAA;QACdlC,UAAU,CAAC4B,YAAY,GAAG,EAAAM,qBAAA,GAAClC,UAAU,CAAC4B,YAAY,cAAAM,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIN,YAAY;MAC3E;MACA,IAAIE,WAAW,EAAE;QAAA,IAAAK,qBAAA;QACbnC,UAAU,CAAC8B,WAAW,GAAG,EAAAK,qBAAA,GAACnC,UAAU,CAAC8B,WAAW,cAAAK,qBAAA,cAAAA,qBAAA,GAAI,CAAC,IAAIL,WAAW;MACxE;IACJ;IACA,MAAMM,WAAW,GAAG3I,UAAU,CAACsG,OAAO,EAAE,IAAI,CAACnC,CAAC,CAAC,CAACyE,GAAG,CAAEC,aAAa,IAAKA,aAAa,CAACD,GAAG,CAAEvB,MAAM;MAAA,IAAAyB,YAAA;MAAA,OAAM;QAClGxB,IAAI,GAAAwB,YAAA,GAAEzB,MAAM,CAACC,IAAI,cAAAwB,YAAA,cAAAA,YAAA,GAAI,EAAE;QACvBC,cAAc,EAAE;UACZC,YAAY,EAAE3B,MAAM,CAACE,aAAa;UAClCC,QAAQ,EAAEH,MAAM,CAACG;QACrB;MACJ,CAAC;IAAA,CAAC,CAAC,CAAC;IACJ,OAAO;MACHmB,WAAW;MACXM,SAAS,EAAE;QAAE1C;MAAW;IAC5B,CAAC;EACL;EACA;EACA,OAAO2C,qBAAqBA,CAACC,KAAK,EAAE9D,OAAO,EAAEe,UAAU,EAAE;IAAA,IAAAgD,gBAAA;IACrD,MAAMjE,MAAM,GAAG;MACX,GAAG,IAAI,CAACC,gBAAgB,CAACC,OAAO,CAAC;MACjCoB,MAAM,EAAE0C,KAAK;MACbrD,MAAM,EAAE;IACZ,CAAC;IACD,MAAMA,MAAM,GAAG,MAAM,IAAI,CAACgB,mBAAmB,CAAC3B,MAAM,EAAEE,OAAO,CAAC;IAC9D,WAAW,MAAMsB,IAAI,IAAIb,MAAM,EAAE;MAAA,IAAAuD,WAAA;MAC7B,MAAMhC,MAAM,GAAGV,IAAI,aAAJA,IAAI,uBAAJA,IAAI,CAAEL,OAAO,CAAC,CAAC,CAAC;MAC/B,IAAI,CAACe,MAAM,EAAE;QACT;MACJ;MACA,MAAMiC,KAAK,GAAG,IAAIzJ,eAAe,CAAC;QAC9ByH,IAAI,EAAED,MAAM,CAACC,IAAI;QACjByB,cAAc,EAAE;UACZC,YAAY,EAAE3B,MAAM,CAACE;QACzB;MACJ,CAAC,CAAC;MACF,MAAM+B,KAAK;MACX;MACA,MAAKlD,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEqB,iBAAiB,EAAA4B,WAAA,GAACC,KAAK,CAAChC,IAAI,cAAA+B,WAAA,cAAAA,WAAA,GAAI,EAAE,CAAC;IACxD;IACA,KAAAD,gBAAA,GAAI/D,OAAO,CAACwC,MAAM,cAAAuB,gBAAA,eAAdA,gBAAA,CAAgBtB,OAAO,EAAE;MACzB,MAAM,IAAItE,KAAK,CAAC,YAAY,CAAC;IACjC;EACJ;EACA,MAAMsD,mBAAmBA,CAACyC,OAAO,EAAElE,OAAO,EAAE;IACxC,MAAMmE,cAAc,GAAG,IAAI,CAACC,iBAAiB,CAACpE,OAAO,CAAC;IACtD,OAAO,IAAI,CAACqE,MAAM,CAACC,IAAI,CAAC,YAAY;MAChC,IAAI;QACA,MAAMC,GAAG,GAAG,MAAM,IAAI,CAACC,MAAM,CAACC,WAAW,CAACC,MAAM,CAACR,OAAO,EAAEC,cAAc,CAAC;QACzE,OAAOI,GAAG;MACd,CAAC,CACD,OAAOI,CAAC,EAAE;QACN,MAAMC,KAAK,GAAG9J,qBAAqB,CAAC6J,CAAC,CAAC;QACtC,MAAMC,KAAK;MACf;IACJ,CAAC,CAAC;EACN;EACA;AACJ;AACA;AACA;AACA;AACA;EACIR,iBAAiBA,CAACpE,OAAO,EAAE;IACvB,IAAI,CAAC,IAAI,CAACwE,MAAM,EAAE;MACd,MAAMK,oBAAoB,GAAG;QACzBpJ,4BAA4B,EAAE,IAAI,CAACA,4BAA4B;QAC/DD,0BAA0B,EAAE,IAAI,CAACA,0BAA0B;QAC3DL,iBAAiB,EAAE,IAAI,CAACA,iBAAiB;QACzCkD,mBAAmB,EAAE,IAAI,CAACA,mBAAmB;QAC7CkB,OAAO,EAAE,IAAI,CAACF,YAAY,CAACE;MAC/B,CAAC;MACD,MAAMuF,QAAQ,GAAGlK,WAAW,CAACiK,oBAAoB,CAAC;MAClD,MAAM/E,MAAM,GAAG;QACX,GAAG,IAAI,CAACT,YAAY;QACpBE,OAAO,EAAEuF,QAAQ;QACjBtG,OAAO,EAAE,IAAI,CAACA,OAAO;QACrBuG,UAAU,EAAE;MAChB,CAAC;MACD,IAAI,CAACjF,MAAM,CAACP,OAAO,EAAE;QACjB,OAAOO,MAAM,CAACP,OAAO;MACzB;MACA,IAAI,CAACiF,MAAM,GAAG,IAAIlK,YAAY,CAACwF,MAAM,CAAC;IAC1C;IACA,MAAMqE,cAAc,GAAG;MACnB,GAAG,IAAI,CAAC9E,YAAY;MACpB,GAAGW;IACP,CAAC;IACD,IAAI,IAAI,CAAC7E,iBAAiB,EAAE;MACxBgJ,cAAc,CAACvE,OAAO,GAAG;QACrB,SAAS,EAAE,IAAI,CAACzE,iBAAiB;QACjC,GAAGgJ,cAAc,CAACvE;MACtB,CAAC;MACDuE,cAAc,CAACa,KAAK,GAAG;QACnB,aAAa,EAAE,IAAI,CAACzJ,qBAAqB;QACzC,GAAG4I,cAAc,CAACa;MACtB,CAAC;IACL;IACA,OAAOb,cAAc;EACzB;EACAc,QAAQA,CAAA,EAAG;IACP,OAAO,QAAQ;EACnB;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}